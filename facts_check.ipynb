{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1, 28, 28]),\n",
       " torch.Size([1000, 1, 28, 28]),\n",
       " torch.Size([1000]),\n",
       " torch.Size([1000]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainTransform  = tv.transforms.Compose([tv.transforms.ToTensor(), tv.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = tv.datasets.MNIST(root='./data',  train=True, download=False, transform=transform)\n",
    "testset = tv.datasets.MNIST(root='./data',  train=False, download=False, transform=transform)\n",
    "\n",
    "# x = trainset[0][0].reshape(28,28)\n",
    "# x.shape\n",
    "\n",
    "# sample\n",
    "idx = np.random.choice(np.arange(len(trainset)), size=1000)\n",
    "trainset = [trainset[i] for i in idx]\n",
    "idx = np.random.choice(np.arange(len(testset)), size=1000)\n",
    "testset = [testset[i] for i in idx]\n",
    "\n",
    "traindata = [i[0].unsqueeze(0) for i in trainset]\n",
    "trainlabel = [i[1] for i in trainset]\n",
    "testdata = [i[0].unsqueeze(0) for i in testset]\n",
    "testlabel = [i[1] for i in testset]\n",
    "\n",
    "X_train = torch.vstack(traindata)\n",
    "y_train = torch.tensor(trainlabel)\n",
    "X_test = torch.vstack(testdata)\n",
    "y_test = torch.tensor(testlabel)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# umap + emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 5, min_dist:0.03, time: 2.309999704360962\n",
      "n_neighbors: 5, min_dist:0.1, time: 2.2879889011383057\n",
      "n_neighbors: 5, min_dist:0.25, time: 2.6669931411743164\n",
      "n_neighbors: 5, min_dist:0.5, time: 2.2809908390045166\n",
      "n_neighbors: 5, min_dist:0.8, time: 2.2739901542663574\n",
      "n_neighbors: 5, min_dist:0.99, time: 2.287997007369995\n",
      "n_neighbors: 10, min_dist:0.03, time: 2.901000738143921\n",
      "n_neighbors: 10, min_dist:0.1, time: 2.440992593765259\n",
      "n_neighbors: 10, min_dist:0.25, time: 2.402992010116577\n",
      "n_neighbors: 10, min_dist:0.5, time: 2.825998306274414\n",
      "n_neighbors: 10, min_dist:0.8, time: 2.397998571395874\n",
      "n_neighbors: 10, min_dist:0.99, time: 2.4529964923858643\n",
      "n_neighbors: 20, min_dist:0.03, time: 2.557995557785034\n",
      "n_neighbors: 20, min_dist:0.1, time: 2.957990884780884\n",
      "n_neighbors: 20, min_dist:0.25, time: 2.5889925956726074\n",
      "n_neighbors: 20, min_dist:0.5, time: 2.5638492107391357\n",
      "n_neighbors: 20, min_dist:0.8, time: 2.8739993572235107\n",
      "n_neighbors: 20, min_dist:0.99, time: 2.5399909019470215\n",
      "n_neighbors: 50, min_dist:0.03, time: 2.811999797821045\n",
      "n_neighbors: 50, min_dist:0.1, time: 2.7769923210144043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\torch\\lib\\site-packages\\seaborn\\axisgrid.py:453: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 50, min_dist:0.25, time: 3.2139925956726074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DV_HL\\utils.py:50: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(dpi=1500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 50, min_dist:0.5, time: 2.801990270614624\n",
      "n_neighbors: 50, min_dist:0.8, time: 2.797992467880249\n",
      "n_neighbors: 50, min_dist:0.99, time: 2.834996461868286\n",
      "n_neighbors: 100, min_dist:0.03, time: 3.3759913444519043\n",
      "n_neighbors: 100, min_dist:0.1, time: 2.984992265701294\n",
      "n_neighbors: 100, min_dist:0.25, time: 3.0069992542266846\n",
      "n_neighbors: 100, min_dist:0.5, time: 2.9509918689727783\n",
      "n_neighbors: 100, min_dist:0.8, time: 3.3719921112060547\n",
      "n_neighbors: 100, min_dist:0.99, time: 3.0249969959259033\n",
      "n_neighbors: 200, min_dist:0.03, time: 3.2029902935028076\n",
      "n_neighbors: 200, min_dist:0.1, time: 3.590991973876953\n",
      "n_neighbors: 200, min_dist:0.25, time: 3.152992010116577\n",
      "n_neighbors: 200, min_dist:0.5, time: 3.43599009513855\n",
      "n_neighbors: 200, min_dist:0.8, time: 3.184990406036377\n",
      "n_neighbors: 200, min_dist:0.99, time: 3.5589921474456787\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "\n",
    "time_cost = []\n",
    "\n",
    "for n in [5, 10, 20, 50, 100, 200]:\n",
    "    \n",
    "    for min_dist in [0.03, 0.1, 0.25, 0.5, 0.8, 0.99]:\n",
    "\n",
    "        t1 = time.time()\n",
    "        reducer = umap.UMAP(n_neighbors=n, min_dist=min_dist, n_components=2, metric='euclidean')\n",
    "        emb = reducer.fit_transform(X_train.view(-1, 28*28))\n",
    "        t2 = time.time()\n",
    "        print(\"n_neighbors: {}, min_dist:{}, time: {}\".format(n, min_dist, t2-t1))\n",
    "        time_cost.append(t2-t1)\n",
    "\n",
    "        draw_z(\n",
    "            z=normalise(emb), \n",
    "            cls=y_train, \n",
    "            s=1, \n",
    "            title=\"n: {}, min_dist: {}, time: {}\".format(n, min_dist, t2-t1), \n",
    "            display=False, \n",
    "            save_path=\"./data/facts_check/vis_umapemb_n{}_mindist{}.png\".format(n, min_dist)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# umap + nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 50, min_dist: 0.03\n",
      "Tue Nov 28 17:38:44 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 17:38:44 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 17:38:44 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 17:38:44 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:15<00:00,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 50, min_dist: 0.1\n",
      "Tue Nov 28 17:49:01 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 17:49:01 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 17:49:01 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 17:49:01 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:20<00:00,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 50, min_dist: 0.25\n",
      "Tue Nov 28 17:59:23 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 17:59:23 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 17:59:23 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 17:59:24 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:15<00:00,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 50, min_dist: 0.5\n",
      "Tue Nov 28 18:09:40 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 18:09:40 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 18:09:40 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 18:09:41 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:14<00:00,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 50, min_dist: 0.8\n",
      "Tue Nov 28 18:19:56 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 18:19:56 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 18:19:56 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 18:19:56 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:17<00:00,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 50, min_dist: 0.99\n",
      "Tue Nov 28 18:30:15 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 18:30:15 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 18:30:15 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 18:30:15 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:19<00:00,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 100, min_dist: 0.03\n",
      "Tue Nov 28 18:40:35 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 18:40:35 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 18:40:36 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 18:40:36 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [40:51<00:00, 24.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 100, min_dist: 0.1\n",
      "Tue Nov 28 19:21:31 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 19:21:31 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 19:21:31 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 19:21:32 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [40:54<00:00, 24.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 100, min_dist: 0.25\n",
      "Tue Nov 28 20:02:29 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 20:02:29 2023 NN descent for 10 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Tue Nov 28 20:02:30 2023 Building RP forest with 7 trees\n",
      "Tue Nov 28 20:02:30 2023 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:31<52:34, 31.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\DV_HL\\facts_check.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_to, batch_from, batch_index_to, batch_index_from, labels, feedback \u001b[39min\u001b[39;00m train_dataset\u001b[39m.\u001b[39mget_batches():\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     embedding_to \u001b[39m=\u001b[39m model(batch_to)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     embedding_from \u001b[39m=\u001b[39m model(batch_from)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(embedding_to, embedding_from)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32md:\\DV_HL\\facts_check.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(x))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear3(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DV_HL/facts_check.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1471\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[0;32m   1470\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1471\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1472\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for n in [5, 10, 20, 50, 100, 200]:\n",
    "for n in [50, 100, 200]:\n",
    "    \n",
    "    for min_dist in [0.03, 0.1, 0.25, 0.5, 0.8, 0.99]:\n",
    "\n",
    "        print(\"n_neighbours: {}, min_dist: {}\".format(n, min_dist))\n",
    "\n",
    "        # 1. dataset\n",
    "        batch_size = 1000 # 1024\n",
    "\n",
    "        # construct graph of nearest neighbors\n",
    "        graph_constructor_train =  ConstructUMAPGraph(metric='euclidean', n_neighbors=n, batch_size=1000, random_state=42)\n",
    "        epochs_per_sample_train, head_train, tail_train, weight_train = graph_constructor_train(X_train)\n",
    "\n",
    "        graph_constructor_test =  ConstructUMAPGraph(metric='euclidean', n_neighbors=n, batch_size=1000, random_state=42)\n",
    "        epochs_per_sample_test, head_test, tail_test, weight_test = graph_constructor_test(X_test)\n",
    "\n",
    "        train_dataset = UMAPDataset(\n",
    "            data=X_train, labels=y_train, \n",
    "            epochs_per_sample=epochs_per_sample_train, head=head_train, tail=tail_train, weight=weight_train, \n",
    "            device='cuda', batch_size=batch_size, feedback=None\n",
    "        )\n",
    "        test_dataset = UMAPDataset(\n",
    "            data=X_test, labels=y_test, \n",
    "            epochs_per_sample=epochs_per_sample_test, head=head_test, tail=tail_test, weight=weight_test, \n",
    "            device='cuda', batch_size=batch_size, feedback=None\n",
    "        )\n",
    "\n",
    "        criterion = UMAPLoss(device='cuda', min_dist=min_dist, batch_size=batch_size, negative_sample_rate=5, edge_weight=None, repulsion_strength=1.0)\n",
    "\n",
    "        # 2. model\n",
    "        class Encoder(nn.Module):\n",
    "\n",
    "            def __init__ (self, output_dim=2):\n",
    "                super().__init__()\n",
    "                self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=2)\n",
    "                self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2)\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.linear1 = nn.Linear(128*6*6, 512)\n",
    "                self.linear2 = nn.Linear(512, 512)\n",
    "                self.linear3 = nn.Linear(512, output_dim)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = F.relu(self.conv1(x))\n",
    "                x = F.relu(self.conv2(x))\n",
    "                x = self.flatten(x)\n",
    "                x = F.relu(self.linear1(x))\n",
    "                x = F.relu(self.linear2(x))\n",
    "                x = F.relu(self.linear3(x))\n",
    "\n",
    "                return x\n",
    "\n",
    "        model = Encoder(output_dim=2).cuda()\n",
    "        # print(model)\n",
    "        # print(\"num params: {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "        # 3. training\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        train_losses = []\n",
    "        for epoch in tqdm(range(100)):\n",
    "            train_loss = 0.\n",
    "            # for batch_to, batch_from in tqdm(train_dataset.get_batches()):\n",
    "            for batch_to, batch_from, batch_index_to, batch_index_from, labels, feedback in train_dataset.get_batches():\n",
    "                optimizer.zero_grad()\n",
    "                embedding_to = model(batch_to)\n",
    "                embedding_from = model(batch_from)\n",
    "                loss = criterion(embedding_to, embedding_from)\n",
    "                train_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            # print('epoch: {}, loss: {}'.format(epoch, train_loss))\n",
    "\n",
    "        torch.save(model.state_dict(), './data/facts_check/umap_n{}_dist{}.pt'.format(n, min_dist))\n",
    "        torch.save(torch.tensor(train_losses), './data/facts_check/loss_umap_n{}_dist{}.pt'.format(n, min_dist))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
