{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier, GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 4), (80, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = np.load(\"./hm_feedback_sim.npy\")\n",
    "bio = np.load(\"./hm_feedback_bio.npy\")\n",
    "\n",
    "sim.shape, bio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train fusion LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((921, 2), (921, 1), (1382, 2), (1382, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 4\n",
    "\n",
    "X_train_mlp = np.load(\"collaboration_with_ting_zhang/result/preds_sim_train_0.{}.npy\".format(ratio))\n",
    "X_train_rf = np.load(\"collaboration_with_ting_zhang/result/rf_pred_train_0.{}.npy\".format(ratio))\n",
    "y_train = np.load(\"collaboration_with_ting_zhang/result/sim_training_label_0.{}.npy\".format(ratio))\n",
    "\n",
    "X_test_mlp = np.load(\"collaboration_with_ting_zhang/result/preds_sim_test_0.{}.npy\".format(10-ratio))\n",
    "X_test_rf = np.load(\"collaboration_with_ting_zhang/result/rf_pred_test_0.{}.npy\".format(10-ratio))\n",
    "y_test = np.load(\"collaboration_with_ting_zhang/result/sim_testing_label_0.{}.npy\".format(10-ratio))\n",
    "\n",
    "X_train = np.hstack([X_train_mlp.reshape(-1,1), X_train_rf.reshape(-1,1)])\n",
    "X_test = np.hstack([X_test_mlp.reshape(-1,1), X_test_rf.reshape(-1,1)])\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - mlp only: 0.997828447339848\n",
      "train - rf only:  1.0\n",
      "test - mlp only: 0.88205499276411\n",
      "test - rf only:  0.9761215629522432\n"
     ]
    }
   ],
   "source": [
    "print(\"train - mlp only:\", accuracy_score(y_true=y_train, y_pred=X_train_mlp.round()))\n",
    "print(\"train - rf only: \", accuracy_score(y_true=y_train, y_pred=X_train_rf.round()))\n",
    "print(\"test - mlp only:\", accuracy_score(y_true=y_test, y_pred=X_test_mlp.round()))\n",
    "print(\"test - rf only: \", accuracy_score(y_true=y_test, y_pred=X_test_rf.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  1.0\n",
      "test acc 0.9319826338639653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "fusion = LogisticRegression()\n",
    "# fusion = RandomForestClassifier()\n",
    "# fusion = SVC(kernel='rbf')\n",
    "# fusion = GaussianProcessClassifier()\n",
    "# fusion = LGBMClassifier()\n",
    "\n",
    "fusion.fit(X_train, y_train.reshape(-1))\n",
    "\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=fusion.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=fusion.predict(X_test))\n",
    "\n",
    "print(\"train acc: \", train_acc)\n",
    "print(\"test acc\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(fusion, open(\"collaboration_with_ting_zhang/result/fusion_0.{}.pkl\".format(ratio), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### error correction module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion_test_pred = fusion.predict(X_test)\n",
    "\n",
    "# for i in range(len(X_test)):\n",
    "#     if fusion_test_pred[i] != sim_test_label[i]:\n",
    "#         print(sim_test_data[i], sim_test_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(torch.from_numpy(X_train), \"collaboration_with_ting_zhang/result/fusion_train_X.pth\")\n",
    "torch.save(torch.from_numpy(y_train), \"collaboration_with_ting_zhang/result/fusion_train_y.pth\")\n",
    "torch.save(torch.from_numpy(X_test), \"collaboration_with_ting_zhang/result/fusion_test_X.pth\")\n",
    "torch.save(torch.from_numpy(y_test), \"collaboration_with_ting_zhang/result/fusion_test_y.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error train:  torch.Size([460, 9]) torch.Size([460, 1])\n",
      "error test:  torch.Size([1843, 9]) torch.Size([1843, 1])\n"
     ]
    }
   ],
   "source": [
    "error_train_X = torch.hstack([\n",
    "    torch.from_numpy(sim_train_data), \n",
    "    torch.from_numpy(X_train), \n",
    "    torch.from_numpy(fusion.predict_proba(X_train)[:,1]).view(-1,1)])\n",
    "error_train_y = torch.from_numpy(y_train) - torch.from_numpy(fusion.predict_proba(X_train)[:,1]).view(-1,1)\n",
    "\n",
    "error_test_X = torch.hstack([\n",
    "    torch.from_numpy(sim_test_data), \n",
    "    torch.from_numpy(X_test), \n",
    "    torch.from_numpy(fusion.predict_proba(X_test)[:,1]).view(-1,1)])\n",
    "error_test_y = torch.from_numpy(y_test) - torch.from_numpy(fusion.predict_proba(X_test)[:,1]).view(-1,1)\n",
    "\n",
    "print(\"error train: \", error_train_X.shape, error_train_y.shape)\n",
    "print(\"error test: \", error_test_X.shape, error_test_y.shape)\n",
    "\n",
    "torch.save(error_train_X, \"collaboration_with_ting_zhang/result/error_train_X.pth\")\n",
    "torch.save(error_train_y, \"collaboration_with_ting_zhang/result/error_train_y.pth\")\n",
    "torch.save(error_test_X, \"collaboration_with_ting_zhang/result/error_test_X.pth\")\n",
    "torch.save(error_test_y, \"collaboration_with_ting_zhang/result/error_test_y.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse:  7.16483782871675e-24\n",
      "test mse 7.16483782871675e-24\n",
      "train acc:  1.0\n",
      "test acc:  0.893651654910472\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# error_corr = LGBMRegressor()\n",
    "error_corr = GaussianProcessRegressor()\n",
    "\n",
    "error_corr.fit(error_train_X, error_train_y.reshape(-1))\n",
    "\n",
    "train_mse = mean_squared_error(y_true=error_train_y, y_pred=error_corr.predict(error_train_X))\n",
    "test_mse = mean_squared_error(y_true=error_test_y, y_pred=error_corr.predict(error_test_X))\n",
    "\n",
    "print(\"train mse: \", train_mse)\n",
    "print(\"test mse\", train_mse)\n",
    "\n",
    "new_pred_train = error_corr.predict(error_train_X) + error_train_X[:, -1].numpy().reshape(-1)\n",
    "new_pred_test = error_corr.predict(error_test_X) + error_test_X[:, -1].numpy().reshape(-1)\n",
    "\n",
    "train_acc = accuracy_score(y_true=y_train.reshape(-1), y_pred=new_pred_train.round())\n",
    "test_acc = accuracy_score(y_true=y_test.reshape(-1), y_pred=new_pred_test.round())\n",
    "\n",
    "print(\"train acc: \", train_acc)\n",
    "print(\"test acc: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_features(x1, x2, mode=0):\n",
    "\n",
    "    # only original feats\n",
    "    if mode==0:\n",
    "        feats = [x1[0], x1[1], x1[2], x2[0], x2[1], x2[2]]\n",
    "\n",
    "    # original feats + cross feats\n",
    "    elif mode==1:\n",
    "        feats = [\n",
    "            x1[0], x1[1], x1[2], \n",
    "            x2[0], x2[1], x2[2], \n",
    "            x1[0]-x2[0], \n",
    "            x1[1]-x2[1], \n",
    "            x1[2]-x2[2], \n",
    "            x1[0]/x2[0], \n",
    "            x1[1]/x2[1], \n",
    "            x1[2]/x2[2], \n",
    "            x1[0]+x1[0]*x1[1]-x1[0]*x1[2], \n",
    "            x2[0]+x2[0]*x2[1]-x2[0]*x2[2], \n",
    "            (x1[0]+x1[0]*x1[1])/x1[0]*x1[2], \n",
    "            (x2[0]+x2[0]*x2[1])/x2[0]*x2[2], \n",
    "            x1[0]*x1[1], \n",
    "            x2[0]*x2[1], \n",
    "            x1[0]*x1[2], \n",
    "            x2[0]*x2[1]\n",
    "        ]\n",
    "\n",
    "    # only cross feats\n",
    "    elif mode==2:\n",
    "        feats = [\n",
    "            # x1[0], x1[1], x1[2], \n",
    "            # x2[0], x2[1], x2[2], \n",
    "            x1[0]-x2[0], \n",
    "            x1[1]-x2[1], \n",
    "            x1[2]-x2[2], \n",
    "            x1[0]/x2[0], \n",
    "            x1[1]/x2[1], \n",
    "            x1[2]/x2[2], \n",
    "            x1[0]+x1[0]*x1[1]-x1[0]*x1[2], \n",
    "            x2[0]+x2[0]*x2[1]-x2[0]*x2[2], \n",
    "            (x1[0]+x1[0]*x1[1])/x1[0]*x1[2], \n",
    "            (x2[0]+x2[0]*x2[1])/x2[0]*x2[2], \n",
    "            x1[0]*x1[1], \n",
    "            x2[0]*x2[1], \n",
    "            x1[0]*x1[2], \n",
    "            x2[0]*x2[1]\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        print(\"wrong mode!\")\n",
    "\n",
    "    return feats\n",
    "\n",
    "def surrogate_inference(models, data, data_maxmin, label_maxmin):\n",
    "    \"\"\"\n",
    "    models: {'mlp': MLP, 'rf': RF, 'fusion': fusion}\n",
    "    data: [N, 6], two sets of parameters, original (non-normalised)\n",
    "    data_maxmin: [2, 6], first row max, second row min\n",
    "    label_maxmin: [2, 1]\n",
    "    : return: [N, 1]\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "\n",
    "    # get p1\n",
    "    with torch.no_grad():\n",
    "        models['mlp'].eval()\n",
    "\n",
    "        data_max, data_min = data_maxmin[0, :], data_maxmin[1, :]\n",
    "        label_max, label_min = label_maxmin[0, :], label_maxmin[1, :]\n",
    "\n",
    "        data_input = (data - data_min) / (data_max - data_min)\n",
    "\n",
    "        p1 = models['mlp'](torch.from_numpy(data_input).float().cuda())\n",
    "        p1 = p1.detach().cpu().numpy() * (label_max - label_min) + label_min\n",
    "        p1 = p1.reshape(-1, 1)\n",
    "\n",
    "    # get p2\n",
    "    if type(data) != type(np.ones(1)):\n",
    "        data = data.detach().cpu().numpy()\n",
    "    data_aug = list(map(lambda x:aug_features(x[:3], x[3:], mode=1), data))\n",
    "    data_aug = np.array(data_aug).reshape(N, -1)\n",
    "    p2 = models['rf'].predict_proba(data_aug)[:, 1]\n",
    "    p2 = p2.reshape(-1, 1)\n",
    "\n",
    "    # get fusion\n",
    "    data_fusion = np.hstack([p1, p2])\n",
    "    p_fusion = models['fusion'].predict_proba(data_fusion)[:, 1]\n",
    "    p_fusion = p_fusion.reshape(-1, 1)\n",
    "\n",
    "    return p_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc 1.0\n",
      "test acc 0.893651654910472\n"
     ]
    }
   ],
   "source": [
    "from collaboration_with_ting_zhang.network_repo import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mlp = MLP_forward_embed([128,64,32,16,1], embedding_dim=int(128/2), input_dim=6).cuda()\n",
    "mlp.load_state_dict(torch.load(\"collaboration_with_ting_zhang/result/20241109_mlp_sim_0.2.pth\"))\n",
    "rf = pickle.load(open(\"collaboration_with_ting_zhang/result/rf.pkl\", \"rb\"))\n",
    "lr = pickle.load(open(\"collaboration_with_ting_zhang/result/fusion.pkl\", \"rb\"))\n",
    "\n",
    "data_maxmin = np.load(\"collaboration_with_ting_zhang/result/sim_training_data_maxmin0.2.npy\")\n",
    "label_maxmin = np.load(\"collaboration_with_ting_zhang/result/sim_training_label_maxmin0.2.npy\")\n",
    "\n",
    "models = {\n",
    "    'mlp': mlp,\n",
    "    'rf': rf,\n",
    "    'fusion': lr\n",
    "}\n",
    "\n",
    "train_pred = surrogate_inference(models, sim_train_data, data_maxmin, label_maxmin)\n",
    "test_pred = surrogate_inference(models, sim_test_data, data_maxmin, label_maxmin)\n",
    "\n",
    "print(\"train acc\", accuracy_score(y_true=sim_train_label, y_pred=train_pred.round()))\n",
    "print(\"test acc\", accuracy_score(y_true=sim_test_label, y_pred=test_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train RF \n",
    "\n",
    "##### on [original + cross feats] with [2:8 train-test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (921, 6) (921, 1)\n",
      "test:  (1382, 6) (1382, 1)\n"
     ]
    }
   ],
   "source": [
    "ratio = 4\n",
    "\n",
    "sim_train_data = np.load(\"collaboration_with_ting_zhang/result/sim_training_data_0.{}.npy\".format(ratio))\n",
    "sim_train_label = np.load(\"collaboration_with_ting_zhang/result/sim_training_label_0.{}.npy\".format(ratio))\n",
    "\n",
    "sim_test_data = np.load(\"collaboration_with_ting_zhang/result/sim_testing_data_0.{}.npy\".format(10-ratio))\n",
    "sim_test_label = np.load(\"collaboration_with_ting_zhang/result/sim_testing_label_0.{}.npy\".format(10-ratio))\n",
    "\n",
    "print(\"train: \", sim_train_data.shape, sim_train_label.shape)\n",
    "print(\"test: \", sim_test_data.shape, sim_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (921, 6) (921, 1)\n",
      "test:  (1382, 6) (1382, 1)\n"
     ]
    }
   ],
   "source": [
    "sim_training_data_maxmin = np.load(\n",
    "    \"collaboration_with_ting_zhang/result/sim_training_data_maxmin0.{}.npy\".format(ratio))\n",
    "sim_training_label_maxmin = np.load(\n",
    "    \"collaboration_with_ting_zhang/result/sim_training_label_maxmin0.{}.npy\".format(ratio))\n",
    "\n",
    "# sim_testing_data_maxmin = np.load(\"collaboration_with_ting_zhang/result/sim_testing_data_maxmin0.8.npy\")\n",
    "# sim_testing_label_maxmin = np.load(\"collaboration_with_ting_zhang/result/sim_testing_data_maxmin0.8.npy\")\n",
    "\n",
    "sim_train_data = sim_train_data * (sim_training_data_maxmin[0, :] - sim_training_data_maxmin[1, :]) \\\n",
    "    + sim_training_data_maxmin[1, :]\n",
    "sim_train_label = sim_train_label * (sim_training_label_maxmin[0, :] - sim_training_label_maxmin[1, :]) \\\n",
    "    + sim_training_label_maxmin[1, :]\n",
    "\n",
    "sim_test_data = sim_test_data * (sim_training_data_maxmin[0, :] - sim_training_data_maxmin[1, :]) \\\n",
    "    + sim_training_data_maxmin[1, :]\n",
    "sim_test_label = sim_test_label * (sim_training_label_maxmin[0, :] - sim_training_label_maxmin[1, :]) \\\n",
    "    + sim_training_label_maxmin[1, :]\n",
    "\n",
    "print(\"train: \", sim_train_data.shape, sim_train_label.shape)\n",
    "print(\"test: \", sim_test_data.shape, sim_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50. ,  1. ,  2. , 10. ,  0.5,  5. ],\n",
       "       [20. , 10. ,  5. , 50. ,  5. ,  2. ],\n",
       "       [50. ,  5. ,  5. , 50. ,  1. ,  5. ],\n",
       "       ...,\n",
       "       [10. ,  5. ,  2. , 10. ,  1. ,  1. ],\n",
       "       [50. ,  1. ,  1. , 20. , 10. ,  1. ],\n",
       "       [10. ,  0.5,  1. , 10. ,  1. ,  2. ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50., 10.,  1., 15., 10.,  5.],\n",
       "       [15.,  1.,  5., 10.,  5.,  1.],\n",
       "       [50.,  1.,  5., 15.,  5.,  2.],\n",
       "       ...,\n",
       "       [15., 10.,  2., 20.,  1.,  1.],\n",
       "       [20., 10.,  2., 20.,  1.,  5.],\n",
       "       [20.,  5.,  1., 50.,  5.,  2.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12\n",
      "2 32\n",
      "4 360\n",
      "5 1187\n",
      "6 1051\n",
      "8 543\n",
      "10 628\n",
      "12 281\n",
      "14 1188\n",
      "15 760\n",
      "16 22\n",
      "17 47\n",
      "18 764\n",
      "21 726\n",
      "22 112\n",
      "24 1085\n",
      "25 254\n",
      "26 630\n",
      "31 208\n",
      "33 661\n",
      "34 240\n",
      "35 1201\n",
      "38 339\n",
      "39 880\n",
      "40 315\n",
      "41 514\n",
      "47 291\n",
      "48 262\n",
      "49 584\n",
      "50 1323\n",
      "51 969\n",
      "52 111\n",
      "53 1299\n",
      "55 15\n",
      "62 1080\n",
      "63 930\n",
      "65 974\n",
      "66 131\n",
      "67 844\n",
      "68 1256\n",
      "69 1121\n",
      "71 186\n",
      "74 1312\n",
      "75 9\n",
      "78 538\n",
      "79 832\n",
      "80 1340\n",
      "82 181\n",
      "83 539\n",
      "84 1349\n",
      "85 1213\n",
      "88 257\n",
      "89 1038\n",
      "90 74\n",
      "91 412\n",
      "92 1013\n",
      "94 174\n",
      "97 1123\n",
      "100 384\n",
      "102 843\n",
      "103 1238\n",
      "104 1023\n",
      "105 1218\n",
      "106 961\n",
      "108 587\n",
      "109 1132\n",
      "110 265\n",
      "111 85\n",
      "112 727\n",
      "114 1093\n",
      "117 755\n",
      "118 467\n",
      "119 997\n",
      "121 644\n",
      "122 372\n",
      "123 687\n",
      "124 858\n",
      "126 598\n",
      "131 1309\n",
      "132 76\n",
      "134 234\n",
      "135 278\n",
      "137 1344\n",
      "138 1300\n",
      "139 474\n",
      "140 579\n",
      "141 903\n",
      "143 686\n",
      "144 447\n",
      "146 498\n",
      "147 193\n",
      "148 348\n",
      "150 1005\n",
      "153 1282\n",
      "155 820\n",
      "156 916\n",
      "157 1381\n",
      "161 624\n",
      "162 94\n",
      "166 523\n",
      "167 162\n",
      "168 177\n",
      "169 90\n",
      "172 295\n",
      "174 92\n",
      "176 1360\n",
      "178 899\n",
      "181 954\n",
      "182 943\n",
      "183 388\n",
      "184 400\n",
      "185 164\n",
      "188 1222\n",
      "189 1075\n",
      "190 1084\n",
      "191 280\n",
      "192 314\n",
      "195 1287\n",
      "197 887\n",
      "198 464\n",
      "199 1356\n",
      "202 1010\n",
      "203 897\n",
      "204 1235\n",
      "206 413\n",
      "208 1303\n",
      "209 1334\n",
      "210 207\n",
      "211 1185\n",
      "212 1116\n",
      "214 221\n",
      "215 1150\n",
      "216 352\n",
      "219 1063\n",
      "220 811\n",
      "221 99\n",
      "223 19\n",
      "224 621\n",
      "225 156\n",
      "227 1224\n",
      "228 381\n",
      "229 516\n",
      "231 347\n",
      "236 1328\n",
      "241 797\n",
      "242 1190\n",
      "243 1109\n",
      "245 1228\n",
      "246 841\n",
      "249 704\n",
      "255 530\n",
      "257 752\n",
      "258 33\n",
      "260 355\n",
      "262 452\n",
      "263 870\n",
      "264 636\n",
      "265 1039\n",
      "268 209\n",
      "269 38\n",
      "271 1313\n",
      "273 590\n",
      "275 1172\n",
      "276 1086\n",
      "278 444\n",
      "279 542\n",
      "281 1210\n",
      "284 821\n",
      "286 175\n",
      "287 197\n",
      "288 1020\n",
      "289 1169\n",
      "290 866\n",
      "292 428\n",
      "293 942\n",
      "294 505\n",
      "295 1042\n",
      "296 1254\n",
      "297 722\n",
      "298 56\n",
      "300 1156\n",
      "303 586\n",
      "304 1368\n",
      "305 367\n",
      "308 288\n",
      "309 532\n",
      "312 569\n",
      "313 709\n",
      "314 229\n",
      "315 495\n",
      "317 770\n",
      "319 650\n",
      "320 272\n",
      "323 977\n",
      "324 158\n",
      "325 602\n",
      "326 1288\n",
      "327 592\n",
      "328 947\n",
      "330 892\n",
      "331 1319\n",
      "332 706\n",
      "334 541\n",
      "335 0\n",
      "338 599\n",
      "339 232\n",
      "340 980\n",
      "342 830\n",
      "343 62\n",
      "345 604\n",
      "346 43\n",
      "347 690\n",
      "349 677\n",
      "351 733\n",
      "352 793\n",
      "354 1055\n",
      "355 871\n",
      "356 491\n",
      "357 1321\n",
      "358 401\n",
      "361 1176\n",
      "362 1045\n",
      "364 1096\n",
      "367 374\n",
      "368 50\n",
      "369 1347\n",
      "374 660\n",
      "375 672\n",
      "377 1314\n",
      "378 338\n",
      "379 1073\n",
      "380 1345\n",
      "382 377\n",
      "383 1041\n",
      "387 748\n",
      "389 1305\n",
      "392 849\n",
      "395 1015\n",
      "396 449\n",
      "397 1064\n",
      "398 1367\n",
      "400 136\n",
      "402 1142\n",
      "403 1177\n",
      "405 356\n",
      "406 589\n",
      "407 320\n",
      "408 376\n",
      "410 1298\n",
      "412 564\n",
      "414 1107\n",
      "416 242\n",
      "418 1178\n",
      "422 655\n",
      "424 223\n",
      "426 216\n",
      "428 852\n",
      "429 715\n",
      "430 466\n",
      "433 13\n",
      "434 988\n",
      "435 1278\n",
      "436 171\n",
      "439 380\n",
      "441 1376\n",
      "442 392\n",
      "443 4\n",
      "445 81\n",
      "447 588\n",
      "449 417\n",
      "452 305\n",
      "453 1250\n",
      "457 122\n",
      "458 435\n",
      "459 378\n",
      "461 558\n",
      "463 1207\n",
      "465 632\n",
      "467 220\n",
      "469 735\n",
      "470 358\n",
      "472 26\n",
      "474 42\n",
      "475 926\n",
      "477 1231\n",
      "479 946\n",
      "480 771\n",
      "483 1027\n",
      "484 673\n",
      "486 490\n",
      "488 1310\n",
      "489 550\n",
      "490 1332\n",
      "493 911\n",
      "498 952\n",
      "501 626\n",
      "502 734\n",
      "503 308\n",
      "505 493\n",
      "506 736\n",
      "508 398\n",
      "510 1259\n",
      "511 1128\n",
      "512 1011\n",
      "514 1374\n",
      "519 1090\n",
      "520 555\n",
      "521 671\n",
      "522 1217\n",
      "524 329\n",
      "526 831\n",
      "527 924\n",
      "531 1267\n",
      "532 1240\n",
      "533 1154\n",
      "534 437\n",
      "535 333\n",
      "537 807\n",
      "538 463\n",
      "543 312\n",
      "544 1211\n",
      "545 613\n",
      "547 79\n",
      "548 776\n",
      "553 468\n",
      "554 1351\n",
      "555 185\n",
      "556 247\n",
      "558 142\n",
      "560 1166\n",
      "561 562\n",
      "562 917\n",
      "563 427\n",
      "567 5\n",
      "568 1047\n",
      "570 1112\n",
      "571 822\n",
      "572 606\n",
      "573 345\n",
      "576 103\n",
      "577 251\n",
      "580 833\n",
      "581 1167\n",
      "583 21\n",
      "585 287\n",
      "587 101\n",
      "588 504\n",
      "589 477\n",
      "591 1275\n",
      "592 405\n",
      "593 49\n",
      "594 1161\n",
      "595 267\n",
      "598 893\n",
      "600 16\n",
      "601 203\n",
      "602 597\n",
      "603 152\n",
      "605 1236\n",
      "606 1171\n",
      "607 273\n",
      "608 303\n",
      "609 829\n",
      "610 149\n",
      "611 438\n",
      "612 54\n",
      "613 885\n",
      "615 713\n",
      "616 881\n",
      "618 137\n",
      "619 750\n",
      "621 353\n",
      "623 517\n",
      "624 685\n",
      "627 777\n",
      "628 425\n",
      "629 204\n",
      "634 1028\n",
      "635 522\n",
      "637 349\n",
      "638 36\n",
      "639 346\n",
      "640 316\n",
      "641 1054\n",
      "644 222\n",
      "645 30\n",
      "646 1380\n",
      "647 905\n",
      "648 73\n",
      "651 250\n",
      "653 879\n",
      "656 1012\n",
      "657 344\n",
      "658 1006\n",
      "660 931\n",
      "664 167\n",
      "665 1290\n",
      "667 802\n",
      "668 230\n",
      "670 126\n",
      "671 153\n",
      "677 1227\n",
      "683 728\n",
      "685 84\n",
      "686 489\n",
      "688 332\n",
      "693 806\n",
      "694 319\n",
      "695 1297\n",
      "696 653\n",
      "697 274\n",
      "699 145\n",
      "700 454\n",
      "701 196\n",
      "703 132\n",
      "704 436\n",
      "705 77\n",
      "707 595\n",
      "708 342\n",
      "709 1204\n",
      "710 387\n",
      "711 1318\n",
      "712 511\n",
      "714 907\n",
      "717 117\n",
      "718 269\n",
      "720 1105\n",
      "723 184\n",
      "725 403\n",
      "727 1032\n",
      "729 1048\n",
      "731 238\n",
      "734 896\n",
      "735 1151\n",
      "737 200\n",
      "739 499\n",
      "740 391\n",
      "741 199\n",
      "743 121\n",
      "747 1252\n",
      "749 1212\n",
      "750 782\n",
      "751 1296\n",
      "752 211\n",
      "753 1365\n",
      "757 932\n",
      "758 1295\n",
      "760 674\n",
      "761 791\n",
      "763 141\n",
      "765 828\n",
      "768 619\n",
      "769 189\n",
      "773 1304\n",
      "775 999\n",
      "781 758\n",
      "782 967\n",
      "783 876\n",
      "786 1329\n",
      "787 1144\n",
      "790 1133\n",
      "791 318\n",
      "792 547\n",
      "793 566\n",
      "794 311\n",
      "795 746\n",
      "797 700\n",
      "798 647\n",
      "800 953\n",
      "801 1065\n",
      "803 506\n",
      "807 244\n",
      "808 1362\n",
      "809 1251\n",
      "812 1146\n",
      "814 1152\n",
      "816 1031\n",
      "817 991\n",
      "818 292\n",
      "820 1074\n",
      "823 1126\n",
      "825 416\n",
      "826 805\n",
      "829 326\n",
      "830 456\n",
      "831 487\n",
      "833 851\n",
      "834 963\n",
      "837 1373\n",
      "838 1220\n",
      "839 836\n",
      "841 1354\n",
      "842 282\n",
      "845 465\n",
      "846 691\n",
      "847 1061\n",
      "848 1114\n",
      "849 981\n",
      "857 1196\n",
      "859 996\n",
      "860 255\n",
      "861 510\n",
      "862 654\n",
      "866 29\n",
      "867 507\n",
      "868 868\n",
      "870 496\n",
      "872 643\n",
      "873 725\n",
      "875 110\n",
      "876 277\n",
      "877 520\n",
      "880 115\n",
      "884 855\n",
      "885 646\n",
      "886 1311\n",
      "887 343\n",
      "888 1357\n",
      "890 410\n",
      "892 322\n",
      "894 1326\n",
      "895 521\n",
      "896 962\n",
      "897 1265\n",
      "898 354\n",
      "900 1262\n",
      "901 1125\n",
      "902 934\n",
      "903 66\n",
      "904 775\n",
      "905 212\n",
      "907 1352\n",
      "908 192\n",
      "909 28\n",
      "910 827\n",
      "912 675\n",
      "913 721\n",
      "914 409\n",
      "916 819\n",
      "539\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(sim_train_data)):\n",
    "    for j in range(len(sim_test_data)):\n",
    "        if np.array_equal(sim_train_data[i], sim_test_data[j]):\n",
    "            print(i, j)\n",
    "            cnt += 1\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (921, 20) (921,)\n",
      "test:  (1382, 20) (1382,)\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for i in range(len(sim_train_data)):\n",
    "    feat = calc_theta_features(x1=sim_train_data[i, :3], x2=sim_train_data[i, 3:], y=sim_train_label.reshape(-1)[i], mode=1)\n",
    "    train.append(np.array(feat))\n",
    "\n",
    "test = []\n",
    "for i in range(len(sim_test_data)):\n",
    "    feat = calc_theta_features(x1=sim_test_data[i, :3], x2=sim_test_data[i, 3:], y=sim_test_label.reshape(-1)[i], mode=1)\n",
    "    test.append(np.array(feat))\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "X_train, y_train = train[:, :-1], train[:, -1]\n",
    "X_test, y_test = test[:, :-1], test[:, -1]\n",
    "\n",
    "print(\"train: \", X_train.shape, y_train.shape)\n",
    "print(\"test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best train acc:  0.996742671009772\n",
      "best test acc:  0.9667149059334298\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n",
      "best param:  50 8 5\n",
      "best train acc:  0.990228013029316\n",
      "best test acc:  0.9688856729377714\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n",
      "best param:  50 12 5\n",
      "best train acc:  0.995656894679696\n",
      "best test acc:  0.9717800289435601\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n",
      "best param:  50 16 2\n",
      "best train acc:  1.0\n",
      "best test acc:  0.9761215629522432\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best = 0.0\n",
    "best_param = []\n",
    "\n",
    "ne_list=[50,100,200]\n",
    "md_list=[8,12,16,32,None]\n",
    "mss_list=[2,5,10,20]\n",
    "\n",
    "for ne in ne_list:\n",
    "    for md in md_list:\n",
    "        for mss in mss_list:\n",
    "                \n",
    "            rf = RandomForestClassifier(n_estimators=ne, max_depth=md, min_samples_split=mss)\n",
    "\n",
    "            rf.fit(X_train, y_train.reshape(-1))\n",
    "            train_acc = accuracy_score(y_true=y_train, y_pred=rf.predict(X_train))\n",
    "            test_acc = accuracy_score(y_true=y_test, y_pred=rf.predict(X_test))\n",
    "            \n",
    "            if test_acc > best:\n",
    "                best = test_acc\n",
    "                best_param = [ne, md, mss]\n",
    "                print(\"best param: \", ne, md, mss)\n",
    "                print(\"best train acc: \", train_acc)\n",
    "                print(\"best test acc: \", test_acc)\n",
    "                print(\"save to collaboration_with_ting_zhang/result/rf.pkl\\n\")\n",
    "                pickle.dump(rf, open(\"collaboration_with_ting_zhang/result/rf_0.{}.pkl\".format(ratio), \"wb\"))\n",
    "                np.save(\"collaboration_with_ting_zhang/result/rf_pred_train_0.{}.npy\".format(ratio), rf.predict_proba(X_train)[:, 1])\n",
    "                np.save(\"collaboration_with_ting_zhang/result/rf_pred_test_0.{}.npy\".format(10-ratio), rf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pair (x1, x2, y)\n",
    "# x1 & x2 are parameters, y=1 if x1 is preferred over x2\n",
    "\n",
    "def calc_theta_features(x1, x2, y, mode=0):\n",
    "\n",
    "    # only original feats\n",
    "    if mode==0:\n",
    "        feats = [x1[0], x1[1], x1[2], x2[0], x2[1], x2[2], y]\n",
    "\n",
    "    # original feats + cross feats\n",
    "    elif mode==1:\n",
    "        feats = [\n",
    "            x1[0], x1[1], x1[2], \n",
    "            x2[0], x2[1], x2[2], \n",
    "            x1[0]-x2[0], \n",
    "            x1[1]-x2[1], \n",
    "            x1[2]-x2[2], \n",
    "            x1[0]/x2[0], \n",
    "            x1[1]/x2[1], \n",
    "            x1[2]/x2[2], \n",
    "            x1[0]+x1[0]*x1[1]-x1[0]*x1[2], \n",
    "            x2[0]+x2[0]*x2[1]-x2[0]*x2[2], \n",
    "            (x1[0]+x1[0]*x1[1])/x1[0]*x1[2], \n",
    "            (x2[0]+x2[0]*x2[1])/x2[0]*x2[2], \n",
    "            x1[0]*x1[1], \n",
    "            x2[0]*x2[1], \n",
    "            x1[0]*x1[2], \n",
    "            x2[0]*x2[1], \n",
    "            y\n",
    "        ]\n",
    "\n",
    "    # only cross feats\n",
    "    elif mode==2:\n",
    "        feats = [\n",
    "            # x1[0], x1[1], x1[2], \n",
    "            # x2[0], x2[1], x2[2], \n",
    "            x1[0]-x2[0], \n",
    "            x1[1]-x2[1], \n",
    "            x1[2]-x2[2], \n",
    "            x1[0]/x2[0], \n",
    "            x1[1]/x2[1], \n",
    "            x1[2]/x2[2], \n",
    "            x1[0]+x1[0]*x1[1]-x1[0]*x1[2], \n",
    "            x2[0]+x2[0]*x2[1]-x2[0]*x2[2], \n",
    "            (x1[0]+x1[0]*x1[1])/x1[0]*x1[2], \n",
    "            (x2[0]+x2[0]*x2[1])/x2[0]*x2[2], \n",
    "            x1[0]*x1[1], \n",
    "            x2[0]*x2[1], \n",
    "            x1[0]*x1[2], \n",
    "            x2[0]*x2[1], \n",
    "            y\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        print(\"wrong mode!\")\n",
    "\n",
    "    return feats\n",
    "\n",
    "def create_pref(data, mode=0):\n",
    "    pairs = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            y = 1 if data[i][-1] > data[j][-1] else 0\n",
    "            pairs.append(calc_theta_features(data[i][:3], data[j][:3], y, mode=mode))\n",
    "    pairs = np.array(pairs)\n",
    "    print(pairs.shape)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sim_data0 \u001b[38;5;241m=\u001b[39m create_pref(\u001b[43msim\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m bio_data0 \u001b[38;5;241m=\u001b[39m create_pref(bio, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m sim_data1 \u001b[38;5;241m=\u001b[39m create_pref(sim, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sim' is not defined"
     ]
    }
   ],
   "source": [
    "sim_data0 = create_pref(sim, mode=0)\n",
    "bio_data0 = create_pref(bio, mode=0)\n",
    "sim_data1 = create_pref(sim, mode=1)\n",
    "bio_data1 = create_pref(bio, mode=1)\n",
    "sim_data2 = create_pref(sim, mode=2)\n",
    "bio_data2 = create_pref(bio, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_rf(ne_list, md_list, mss_list, X, y, cv=5):\n",
    "\n",
    "    best = [0.0, 0.0]\n",
    "    best_param = []\n",
    "\n",
    "    for ne in ne_list:\n",
    "        for md in md_list:\n",
    "            for mss in mss_list:\n",
    "                    \n",
    "                    rf = RandomForestClassifier(n_estimators=ne, max_depth=md, min_samples_split=mss)\n",
    "\n",
    "                    scores = cross_val_score(rf, X, y, cv=cv)\n",
    "                    if scores.mean() > best[0]:\n",
    "                        best = [scores.mean(), scores.std()]\n",
    "                        best_param = [ne, md, mss]\n",
    "                        print(\"best param: \", ne, md, mss)\n",
    "                        print(\"best acc: \", best[0], best[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.9218956898990852 0.02865741467929385\n",
      "best param:  50 8 5\n",
      "best acc:  0.9236310478166556 0.025175969011542627\n",
      "best param:  50 8 10\n",
      "best acc:  0.9249306799962275 0.030736953884597025\n",
      "best param:  50 12 2\n",
      "best acc:  0.925804017730831 0.033036644254497524\n",
      "best param:  50 12 5\n",
      "best acc:  0.9292728473073659 0.0322930152890416\n",
      "best param:  50 16 2\n",
      "best acc:  0.9323097236631142 0.02480482307886147\n",
      "best param:  100 32 2\n",
      "best acc:  0.9336112421012921 0.023845984313836176\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data0[:, :-1], sim_data0[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.9366518909742526 0.03668526283071027\n",
      "best param:  50 12 2\n",
      "best acc:  0.9500971423182119 0.02711803247544511\n",
      "best param:  100 32 2\n",
      "best acc:  0.9514014901442988 0.022389563171431728\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data1[:, :-1], sim_data1[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.9288371215693673 0.036986646263492455\n",
      "best param:  50 8 5\n",
      "best acc:  0.9297048005281525 0.038119665014149526\n",
      "best param:  50 12 2\n",
      "best acc:  0.9388163727247004 0.028414689358960674\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data2[:, :-1], sim_data2[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  1.0\n",
      "test acc:  0.952819956616052\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sim_data2[:, :-1], sim_data2[:, -1], test_size=0.8, random_state=114514)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=1)\n",
    "\n",
    "rf.fit(X_train, y_train.reshape(-1))\n",
    "print(\"train acc: \", accuracy_score(y_true=y_train, y_pred=rf.predict(X_train)))\n",
    "print(\"test acc: \", accuracy_score(y_true=y_test, y_pred=rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.72046875 0.014785246552729525\n",
      "best param:  50 8 20\n",
      "best acc:  0.72265625 0.026773062488254885\n",
      "best param:  100 8 10\n",
      "best acc:  0.7254687500000001 0.021950761661044944\n",
      "best param:  200 8 10\n",
      "best acc:  0.72609375 0.023147159990482603\n",
      "best param:  200 8 20\n",
      "best acc:  0.7284375 0.025129547163150388\n"
     ]
    }
   ],
   "source": [
    "X, y = bio_data0[:, :-1], bio_data0[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.714375 0.06656249999999998\n",
      "best param:  50 8 5\n",
      "best acc:  0.71671875 0.07061670305246488\n",
      "best param:  50 8 20\n",
      "best acc:  0.7215625 0.06061332039556155\n",
      "best param:  100 8 10\n",
      "best acc:  0.7225 0.06354094091115585\n"
     ]
    }
   ],
   "source": [
    "X, y = bio_data1[:, :-1], bio_data1[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.7120312500000001 0.061292236712735496\n",
      "best param:  50 8 5\n",
      "best acc:  0.724375 0.06192982104265277\n",
      "best param:  50 8 20\n",
      "best acc:  0.7259375 0.05306384347533636\n"
     ]
    }
   ],
   "source": [
    "X, y = bio_data2[:, :-1], bio_data2[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  0.8875\n",
      "test acc:  0.8123046875\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    bio_data2[:, :-1], bio_data2[:, -1], test_size=0.8, random_state=114514)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=8, min_samples_split=10)\n",
    "\n",
    "rf.fit(X_train, y_train.reshape(-1))\n",
    "print(\"train acc: \", accuracy_score(y_true=y_train, y_pred=rf.predict(X_train)))\n",
    "print(\"test acc: \", accuracy_score(y_true=y_test, y_pred=rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.746875  , 0.7390625 , 0.78203125, 0.59375   , 0.703125  ]),\n",
       " 0.7129687499999999,\n",
       " 0.06466862647373917)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X=bio_data2[:, :-1], y=bio_data2[:, -1], cv=5)\n",
    "scores, scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_gp(kernel_list, X, y, cv=5):\n",
    "\n",
    "    best = [0.0, 0.0]\n",
    "    best_param = []\n",
    "\n",
    "    for kernel in kernel_list:\n",
    "                \n",
    "        gpc = GaussianProcessClassifier(kernel=kernel).fit(X, y)\n",
    "\n",
    "        scores = cross_val_score(gpc, X, y, cv=cv)\n",
    "        if scores.mean() > best[0]:\n",
    "            best = [scores.mean(), scores.std()]\n",
    "            print(\"best kernel: \", kernel)\n",
    "            print(\"best acc: \", best[0], best[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_list = [\n",
    "    1.0 * RBF(1.0), \n",
    "    1.0 * Matern(1.0), \n",
    "    1.0 * RationalQuadratic(1.0), \n",
    "    1.0 * ExpSineSquared(1.0), \n",
    "    1.0 * DotProduct(1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best kernel:  1**2 * RBF(length_scale=1)\n",
      "best acc:  0.6141497689333207 0.0005338111855135441\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data0[:, :-1], sim_data0[:, -1]\n",
    "\n",
    "cross_val_gp(kernel_list=kernel_list, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best kernel:  1**2 * RBF(length_scale=1)\n",
      "best acc:  0.6141497689333207 0.0005338111855135441\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data1[:, :-1], sim_data1[:, -1]\n",
    "\n",
    "cross_val_gp(kernel_list=kernel_list, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best kernel:  1**2 * RBF(length_scale=1)\n",
      "best acc:  0.6884375 0.0003125000000000267\n"
     ]
    }
   ],
   "source": [
    "X, y = bio_data0[:, :-1], bio_data0[:, -1]\n",
    "\n",
    "cross_val_gp(kernel_list=kernel_list, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = bio_data1[:, :-1], bio_data1[:, -1]\n",
    "\n",
    "cross_val_gp(kernel_list=kernel_list, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
