{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier, GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 4), (80, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = np.load(\"./hm_feedback_sim.npy\")\n",
    "bio = np.load(\"./hm_feedback_bio.npy\")\n",
    "\n",
    "sim.shape, bio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train fusion LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((460, 2), (460, 1), (1843, 2), (1843, 1))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mlp = np.load(\"collaboration_with_ting_zhang/result/preds_sim_train_0.2.npy\")\n",
    "X_train_rf = np.load(\"collaboration_with_ting_zhang/result/rf_pred_train_0.2.npy\")\n",
    "y_train = np.load(\"collaboration_with_ting_zhang/result/sim_training_label_0.2.npy\")\n",
    "\n",
    "X_test_mlp = np.load(\"collaboration_with_ting_zhang/result/preds_sim_test_0.8.npy\")\n",
    "X_test_rf = np.load(\"collaboration_with_ting_zhang/result/rf_pred_test_0.8.npy\")\n",
    "y_test = np.load(\"collaboration_with_ting_zhang/result/sim_testing_label_0.8.npy\")\n",
    "\n",
    "X_train = np.hstack([X_train_mlp.reshape(-1,1), X_train_rf.reshape(-1,1)])\n",
    "X_test = np.hstack([X_test_mlp.reshape(-1,1), X_test_rf.reshape(-1,1)])\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - mlp only: 1.0\n",
      "train - rf only:  0.9934782608695653\n",
      "test - mlp only: 0.8643516006511123\n",
      "test - rf only:  0.951709169831796\n"
     ]
    }
   ],
   "source": [
    "print(\"train - mlp only:\", accuracy_score(y_true=y_train, y_pred=X_train_mlp.round()))\n",
    "print(\"train - rf only: \", accuracy_score(y_true=y_train, y_pred=X_train_rf.round()))\n",
    "print(\"test - mlp only:\", accuracy_score(y_true=y_test, y_pred=X_test_mlp.round()))\n",
    "print(\"test - rf only: \", accuracy_score(y_true=y_test, y_pred=X_test_rf.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - mlp only: 1.0\n",
      "train - rf only:  0.9934782608695653\n",
      "test - mlp only: 0.8643516006511123\n",
      "test - rf only:  0.951709169831796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "fusion = LogisticRegression()\n",
    "# fusion = RandomForestClassifier()\n",
    "# fusion = SVC(kernel='rbf')\n",
    "# fusion = GaussianProcessClassifier()\n",
    "# fusion = LGBMClassifier()\n",
    "\n",
    "fusion.fit(X_train, y_train.reshape(-1))\n",
    "\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=fusion.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=fusion.predict(X_test))\n",
    "\n",
    "print(\"train acc: \", train_acc)\n",
    "print(\"test acc\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion_test_pred = fusion.predict(X_test)\n",
    "\n",
    "# for i in range(len(X_test)):\n",
    "#     if fusion_test_pred[i] != sim_test_label[i]:\n",
    "#         print(sim_test_data[i], sim_test_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(torch.from_numpy(X_train), \"collaboration_with_ting_zhang/result/fusion_train_X.pth\")\n",
    "torch.save(torch.from_numpy(y_train), \"collaboration_with_ting_zhang/result/fusion_train_y.pth\")\n",
    "torch.save(torch.from_numpy(X_test), \"collaboration_with_ting_zhang/result/fusion_test_X.pth\")\n",
    "torch.save(torch.from_numpy(y_test), \"collaboration_with_ting_zhang/result/fusion_test_y.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error train:  torch.Size([460, 9]) torch.Size([460, 1])\n",
      "error test:  torch.Size([1843, 9]) torch.Size([1843, 1])\n"
     ]
    }
   ],
   "source": [
    "error_train_X = torch.hstack([\n",
    "    torch.from_numpy(sim_train_data), \n",
    "    torch.from_numpy(X_train), \n",
    "    torch.from_numpy(fusion.predict_proba(X_train)[:,1]).view(-1,1)])\n",
    "error_train_y = torch.from_numpy(y_train) - torch.from_numpy(fusion.predict_proba(X_train)[:,1]).view(-1,1)\n",
    "\n",
    "error_test_X = torch.hstack([\n",
    "    torch.from_numpy(sim_test_data), \n",
    "    torch.from_numpy(X_test), \n",
    "    torch.from_numpy(fusion.predict_proba(X_test)[:,1]).view(-1,1)])\n",
    "error_test_y = torch.from_numpy(y_test) - torch.from_numpy(fusion.predict_proba(X_test)[:,1]).view(-1,1)\n",
    "\n",
    "print(\"error train: \", error_train_X.shape, error_train_y.shape)\n",
    "print(\"error test: \", error_test_X.shape, error_test_y.shape)\n",
    "\n",
    "torch.save(error_train_X, \"collaboration_with_ting_zhang/result/error_train_X.pth\")\n",
    "torch.save(error_train_y, \"collaboration_with_ting_zhang/result/error_train_y.pth\")\n",
    "torch.save(error_test_X, \"collaboration_with_ting_zhang/result/error_test_X.pth\")\n",
    "torch.save(error_test_y, \"collaboration_with_ting_zhang/result/error_test_y.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse:  7.16483782871675e-24\n",
      "test mse 7.16483782871675e-24\n",
      "train acc:  1.0\n",
      "test acc:  0.893651654910472\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# error_corr = LGBMRegressor()\n",
    "error_corr = GaussianProcessRegressor()\n",
    "\n",
    "error_corr.fit(error_train_X, error_train_y.reshape(-1))\n",
    "\n",
    "train_mse = mean_squared_error(y_true=error_train_y, y_pred=error_corr.predict(error_train_X))\n",
    "test_mse = mean_squared_error(y_true=error_test_y, y_pred=error_corr.predict(error_test_X))\n",
    "\n",
    "print(\"train mse: \", train_mse)\n",
    "print(\"test mse\", train_mse)\n",
    "\n",
    "new_pred_train = error_corr.predict(error_train_X) + error_train_X[:, -1].numpy().reshape(-1)\n",
    "new_pred_test = error_corr.predict(error_test_X) + error_test_X[:, -1].numpy().reshape(-1)\n",
    "\n",
    "train_acc = accuracy_score(y_true=y_train.reshape(-1), y_pred=new_pred_train.round())\n",
    "test_acc = accuracy_score(y_true=y_test.reshape(-1), y_pred=new_pred_test.round())\n",
    "\n",
    "print(\"train acc: \", train_acc)\n",
    "print(\"test acc: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train RF \n",
    "\n",
    "##### on [original + cross feats] with [2:8 train-test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (460, 6) (460, 1)\n",
      "test:  (1843, 6) (1843, 1)\n"
     ]
    }
   ],
   "source": [
    "sim_train_data = np.load(\"collaboration_with_ting_zhang/result/sim_training_data_0.2.npy\")\n",
    "sim_train_label = np.load(\"collaboration_with_ting_zhang/result/sim_training_label_0.2.npy\")\n",
    "\n",
    "sim_test_data = np.load(\"collaboration_with_ting_zhang/result/sim_testing_data_0.8.npy\")\n",
    "sim_test_label = np.load(\"collaboration_with_ting_zhang/result/sim_testing_label_0.8.npy\")\n",
    "\n",
    "print(\"train: \", sim_train_data.shape, sim_train_label.shape)\n",
    "print(\"test: \", sim_test_data.shape, sim_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (460, 6) (460, 1)\n",
      "test:  (1843, 6) (1843, 1)\n"
     ]
    }
   ],
   "source": [
    "sim_training_data_maxmin = np.load(\"collaboration_with_ting_zhang/result/sim_training_data_maxmin0.2.npy\")\n",
    "sim_training_label_maxmin = np.load(\"collaboration_with_ting_zhang/result/sim_training_label_maxmin0.2.npy\")\n",
    "\n",
    "# sim_testing_data_maxmin = np.load(\"collaboration_with_ting_zhang/result/sim_testing_data_maxmin0.8.npy\")\n",
    "# sim_testing_label_maxmin = np.load(\"collaboration_with_ting_zhang/result/sim_testing_data_maxmin0.8.npy\")\n",
    "\n",
    "sim_train_data = sim_train_data * (sim_training_data_maxmin[0, :] - sim_training_data_maxmin[1, :]) \\\n",
    "    + sim_training_data_maxmin[1, :]\n",
    "sim_train_label = sim_train_label * (sim_training_label_maxmin[0, :] - sim_training_label_maxmin[1, :]) \\\n",
    "    + sim_training_label_maxmin[1, :]\n",
    "\n",
    "sim_test_data = sim_test_data * (sim_training_data_maxmin[0, :] - sim_training_data_maxmin[1, :]) \\\n",
    "    + sim_training_data_maxmin[1, :]\n",
    "sim_test_label = sim_test_label * (sim_training_label_maxmin[0, :] - sim_training_label_maxmin[1, :]) \\\n",
    "    + sim_training_label_maxmin[1, :]\n",
    "\n",
    "print(\"train: \", sim_train_data.shape, sim_train_label.shape)\n",
    "print(\"test: \", sim_test_data.shape, sim_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50. ,  1. ,  2. , 10. ,  0.5,  5. ],\n",
       "       [20. , 10. ,  5. , 50. ,  5. ,  2. ],\n",
       "       [50. ,  5. ,  5. , 50. ,  1. ,  5. ],\n",
       "       ...,\n",
       "       [10. ,  0.5,  2. , 50. , 10. ,  2. ],\n",
       "       [15. ,  5. ,  5. , 10. ,  1. ,  5. ],\n",
       "       [15. ,  1. ,  5. , 15. , 10. ,  5. ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 473\n",
      "1 134\n",
      "2 493\n",
      "4 821\n",
      "5 1648\n",
      "6 1512\n",
      "7 162\n",
      "8 1004\n",
      "10 1089\n",
      "11 67\n",
      "12 742\n",
      "14 1649\n",
      "15 1221\n",
      "16 483\n",
      "17 508\n",
      "18 1225\n",
      "19 93\n",
      "20 286\n",
      "21 1187\n",
      "22 573\n",
      "24 1546\n",
      "25 715\n",
      "26 1091\n",
      "29 443\n",
      "31 669\n",
      "33 1122\n",
      "34 701\n",
      "35 1662\n",
      "36 75\n",
      "38 800\n",
      "39 1341\n",
      "40 776\n",
      "41 975\n",
      "42 183\n",
      "44 49\n",
      "46 5\n",
      "47 752\n",
      "48 723\n",
      "49 1045\n",
      "50 1784\n",
      "51 1430\n",
      "52 572\n",
      "53 1760\n",
      "54 211\n",
      "55 476\n",
      "56 397\n",
      "59 104\n",
      "60 100\n",
      "61 101\n",
      "62 1541\n",
      "63 1391\n",
      "64 23\n",
      "65 1435\n",
      "66 592\n",
      "67 1305\n",
      "68 1717\n",
      "69 1582\n",
      "70 259\n",
      "71 647\n",
      "74 1773\n",
      "75 470\n",
      "78 999\n",
      "79 1293\n",
      "80 1801\n",
      "81 297\n",
      "82 642\n",
      "83 1000\n",
      "84 1810\n",
      "85 1674\n",
      "88 718\n",
      "89 1499\n",
      "90 535\n",
      "91 873\n",
      "92 1474\n",
      "94 635\n",
      "95 400\n",
      "97 1584\n",
      "99 369\n",
      "100 845\n",
      "102 1304\n",
      "103 1699\n",
      "104 1484\n",
      "105 1679\n",
      "106 1422\n",
      "107 423\n",
      "108 1048\n",
      "109 1593\n",
      "110 726\n",
      "111 546\n",
      "112 1188\n",
      "113 311\n",
      "114 1554\n",
      "115 313\n",
      "116 322\n",
      "117 1216\n",
      "118 928\n",
      "119 1458\n",
      "121 1105\n",
      "122 833\n",
      "123 1148\n",
      "124 1319\n",
      "126 1059\n",
      "127 299\n",
      "129 438\n",
      "130 414\n",
      "131 1770\n",
      "132 537\n",
      "133 453\n",
      "134 695\n",
      "135 739\n",
      "136 232\n",
      "137 1805\n",
      "138 1761\n",
      "139 935\n",
      "140 1040\n",
      "141 1364\n",
      "142 329\n",
      "143 1147\n",
      "144 908\n",
      "145 169\n",
      "146 959\n",
      "147 654\n",
      "148 809\n",
      "149 187\n",
      "150 1466\n",
      "151 39\n",
      "152 167\n",
      "153 1743\n",
      "154 155\n",
      "155 1281\n",
      "156 1377\n",
      "157 1842\n",
      "159 146\n",
      "160 309\n",
      "161 1085\n",
      "162 555\n",
      "164 153\n",
      "166 984\n",
      "167 623\n",
      "168 638\n",
      "169 551\n",
      "172 756\n",
      "173 159\n",
      "174 553\n",
      "176 1821\n",
      "177 261\n",
      "178 1360\n",
      "179 199\n",
      "180 214\n",
      "181 1415\n",
      "182 1404\n",
      "183 849\n",
      "184 861\n",
      "185 625\n",
      "188 1683\n",
      "189 1536\n",
      "190 1545\n",
      "191 741\n",
      "192 775\n",
      "194 124\n",
      "195 1748\n",
      "196 432\n",
      "197 1348\n",
      "198 925\n",
      "199 1817\n",
      "200 188\n",
      "201 89\n",
      "202 1471\n",
      "203 1358\n",
      "204 1696\n",
      "205 54\n",
      "206 874\n",
      "208 1764\n",
      "209 1795\n",
      "210 668\n",
      "211 1646\n",
      "212 1577\n",
      "213 147\n",
      "214 682\n",
      "215 1611\n",
      "216 813\n",
      "218 44\n",
      "219 1524\n",
      "220 1272\n",
      "221 560\n",
      "223 480\n",
      "224 1082\n",
      "225 617\n",
      "226 431\n",
      "227 1685\n",
      "228 842\n",
      "229 977\n",
      "230 418\n",
      "231 808\n",
      "232 112\n",
      "236 1789\n",
      "237 445\n",
      "239 45\n",
      "240 207\n",
      "241 1258\n",
      "242 1651\n",
      "243 1570\n",
      "244 298\n",
      "245 1689\n",
      "246 1302\n",
      "247 401\n",
      "248 181\n",
      "249 1165\n",
      "250 221\n",
      "251 177\n",
      "252 65\n",
      "253 149\n",
      "254 119\n",
      "255 991\n",
      "257 1213\n",
      "258 494\n",
      "260 816\n",
      "261 428\n",
      "262 913\n",
      "263 1331\n",
      "264 1097\n",
      "265 1500\n",
      "267 105\n",
      "268 670\n",
      "269 499\n",
      "271 1774\n",
      "272 80\n",
      "273 1051\n",
      "275 1633\n",
      "276 1547\n",
      "278 905\n",
      "279 1003\n",
      "280 172\n",
      "281 1671\n",
      "284 1282\n",
      "285 217\n",
      "286 636\n",
      "287 658\n",
      "288 1481\n",
      "289 1630\n",
      "290 1327\n",
      "292 889\n",
      "293 1403\n",
      "294 966\n",
      "295 1503\n",
      "296 1715\n",
      "297 1183\n",
      "298 517\n",
      "299 245\n",
      "300 1617\n",
      "303 1047\n",
      "304 1829\n",
      "305 828\n",
      "306 64\n",
      "308 749\n",
      "309 993\n",
      "312 1030\n",
      "313 1170\n",
      "314 690\n",
      "315 956\n",
      "317 1231\n",
      "319 1111\n",
      "320 733\n",
      "321 212\n",
      "323 1438\n",
      "324 619\n",
      "325 1063\n",
      "326 1749\n",
      "327 1053\n",
      "328 1408\n",
      "330 1353\n",
      "331 1780\n",
      "332 1167\n",
      "334 1002\n",
      "335 461\n",
      "337 9\n",
      "338 1060\n",
      "339 693\n",
      "340 1441\n",
      "341 241\n",
      "342 1291\n",
      "343 523\n",
      "344 388\n",
      "345 1065\n",
      "346 504\n",
      "347 1151\n",
      "349 1138\n",
      "351 1194\n",
      "352 1254\n",
      "354 1516\n",
      "355 1332\n",
      "356 952\n",
      "357 1782\n",
      "358 862\n",
      "359 143\n",
      "360 198\n",
      "361 1637\n",
      "362 1506\n",
      "364 1557\n",
      "367 835\n",
      "368 511\n",
      "369 1808\n",
      "370 242\n",
      "371 387\n",
      "372 293\n",
      "373 102\n",
      "374 1121\n",
      "375 1133\n",
      "377 1775\n",
      "378 799\n",
      "379 1534\n",
      "380 1806\n",
      "381 410\n",
      "382 838\n",
      "383 1502\n",
      "384 150\n",
      "387 1209\n",
      "388 317\n",
      "389 1766\n",
      "392 1310\n",
      "393 57\n",
      "395 1476\n",
      "396 910\n",
      "397 1525\n",
      "398 1828\n",
      "399 449\n",
      "400 597\n",
      "402 1603\n",
      "403 1638\n",
      "404 332\n",
      "405 817\n",
      "406 1050\n",
      "407 781\n",
      "408 837\n",
      "410 1759\n",
      "412 1025\n",
      "413 27\n",
      "414 1568\n",
      "415 35\n",
      "416 703\n",
      "417 228\n",
      "418 1639\n",
      "421 1\n",
      "422 1116\n",
      "423 370\n",
      "424 684\n",
      "426 677\n",
      "428 1313\n",
      "429 1176\n",
      "430 927\n",
      "432 448\n",
      "433 474\n",
      "434 1449\n",
      "435 1739\n",
      "436 632\n",
      "438 103\n",
      "439 841\n",
      "441 1837\n",
      "442 853\n",
      "443 465\n",
      "444 264\n",
      "445 542\n",
      "447 1049\n",
      "449 878\n",
      "450 131\n",
      "451 110\n",
      "452 766\n",
      "453 1711\n",
      "456 226\n",
      "457 583\n",
      "458 896\n",
      "459 839\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(sim_train_data)):\n",
    "    for j in range(len(sim_test_data)):\n",
    "        if np.array_equal(sim_train_data[i], sim_test_data[j]):\n",
    "            print(i, j)\n",
    "            cnt += 1\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (460, 20) (460,)\n",
      "test:  (1843, 20) (1843,)\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for i in range(len(sim_train_data)):\n",
    "    feat = calc_theta_features(x1=sim_train_data[i, :3], x2=sim_train_data[i, 3:], y=sim_train_label.reshape(-1)[i], mode=1)\n",
    "    train.append(np.array(feat))\n",
    "\n",
    "test = []\n",
    "for i in range(len(sim_test_data)):\n",
    "    feat = calc_theta_features(x1=sim_test_data[i, :3], x2=sim_test_data[i, 3:], y=sim_test_label.reshape(-1)[i], mode=1)\n",
    "    test.append(np.array(feat))\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "X_train, y_train = train[:, :-1], train[:, -1]\n",
    "X_test, y_test = test[:, :-1], test[:, -1]\n",
    "\n",
    "print(\"train: \", X_train.shape, y_train.shape)\n",
    "print(\"test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best train acc:  0.9956521739130435\n",
      "best test acc:  0.9413998914812806\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n",
      "best param:  50 8 5\n",
      "best train acc:  0.991304347826087\n",
      "best test acc:  0.9419424850786761\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n",
      "best param:  50 16 2\n",
      "best train acc:  1.0\n",
      "best test acc:  0.9506239826370049\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n",
      "best param:  50 None 2\n",
      "best train acc:  1.0\n",
      "best test acc:  0.9511665762344005\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n",
      "best param:  50 None 5\n",
      "best train acc:  0.9934782608695653\n",
      "best test acc:  0.951709169831796\n",
      "save to collaboration_with_ting_zhang/result/rf.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best = 0.0\n",
    "best_param = []\n",
    "\n",
    "ne_list=[50,100,200]\n",
    "md_list=[8,12,16,32,None]\n",
    "mss_list=[2,5,10,20]\n",
    "\n",
    "for ne in ne_list:\n",
    "    for md in md_list:\n",
    "        for mss in mss_list:\n",
    "                \n",
    "            rf = RandomForestClassifier(n_estimators=ne, max_depth=md, min_samples_split=mss)\n",
    "\n",
    "            rf.fit(X_train, y_train.reshape(-1))\n",
    "            train_acc = accuracy_score(y_true=y_train, y_pred=rf.predict(X_train))\n",
    "            test_acc = accuracy_score(y_true=y_test, y_pred=rf.predict(X_test))\n",
    "            \n",
    "            if test_acc > best:\n",
    "                best = test_acc\n",
    "                best_param = [ne, md, mss]\n",
    "                print(\"best param: \", ne, md, mss)\n",
    "                print(\"best train acc: \", train_acc)\n",
    "                print(\"best test acc: \", test_acc)\n",
    "                print(\"save to collaboration_with_ting_zhang/result/rf.pkl\\n\")\n",
    "                pickle.dump(rf, open(\"collaboration_with_ting_zhang/result/rf.pkl\", \"wb\"))\n",
    "                np.save(\"collaboration_with_ting_zhang/result/rf_pred_train_0.2.npy\", rf.predict_proba(X_train)[:, 1])\n",
    "                np.save(\"collaboration_with_ting_zhang/result/rf_pred_test_0.8.npy\", rf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pair (x1, x2, y)\n",
    "# x1 & x2 are parameters, y=1 if x1 is preferred over x2\n",
    "\n",
    "def calc_theta_features(x1, x2, y, mode=0):\n",
    "\n",
    "    # only original feats\n",
    "    if mode==0:\n",
    "        feats = [x1[0], x1[1], x1[2], x2[0], x2[1], x2[2], y]\n",
    "\n",
    "    # original feats + cross feats\n",
    "    elif mode==1:\n",
    "        feats = [\n",
    "            x1[0], x1[1], x1[2], \n",
    "            x2[0], x2[1], x2[2], \n",
    "            x1[0]-x2[0], \n",
    "            x1[1]-x2[1], \n",
    "            x1[2]-x2[2], \n",
    "            x1[0]/x2[0], \n",
    "            x1[1]/x2[1], \n",
    "            x1[2]/x2[2], \n",
    "            x1[0]+x1[0]*x1[1]-x1[0]*x1[2], \n",
    "            x2[0]+x2[0]*x2[1]-x2[0]*x2[2], \n",
    "            (x1[0]+x1[0]*x1[1])/x1[0]*x1[2], \n",
    "            (x2[0]+x2[0]*x2[1])/x2[0]*x2[2], \n",
    "            x1[0]*x1[1], \n",
    "            x2[0]*x2[1], \n",
    "            x1[0]*x1[2], \n",
    "            x2[0]*x2[1], \n",
    "            y\n",
    "        ]\n",
    "\n",
    "    # only cross feats\n",
    "    elif mode==2:\n",
    "        feats = [\n",
    "            # x1[0], x1[1], x1[2], \n",
    "            # x2[0], x2[1], x2[2], \n",
    "            x1[0]-x2[0], \n",
    "            x1[1]-x2[1], \n",
    "            x1[2]-x2[2], \n",
    "            x1[0]/x2[0], \n",
    "            x1[1]/x2[1], \n",
    "            x1[2]/x2[2], \n",
    "            x1[0]+x1[0]*x1[1]-x1[0]*x1[2], \n",
    "            x2[0]+x2[0]*x2[1]-x2[0]*x2[2], \n",
    "            (x1[0]+x1[0]*x1[1])/x1[0]*x1[2], \n",
    "            (x2[0]+x2[0]*x2[1])/x2[0]*x2[2], \n",
    "            x1[0]*x1[1], \n",
    "            x2[0]*x2[1], \n",
    "            x1[0]*x1[2], \n",
    "            x2[0]*x2[1], \n",
    "            y\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        print(\"wrong mode!\")\n",
    "\n",
    "    return feats\n",
    "\n",
    "def create_pref(data, mode=0):\n",
    "    pairs = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            y = 1 if data[i][-1] > data[j][-1] else 0\n",
    "            pairs.append(calc_theta_features(data[i][:3], data[j][:3], y, mode=mode))\n",
    "    pairs = np.array(pairs)\n",
    "    print(pairs.shape)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sim_data0 \u001b[38;5;241m=\u001b[39m create_pref(\u001b[43msim\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m bio_data0 \u001b[38;5;241m=\u001b[39m create_pref(bio, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m sim_data1 \u001b[38;5;241m=\u001b[39m create_pref(sim, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sim' is not defined"
     ]
    }
   ],
   "source": [
    "sim_data0 = create_pref(sim, mode=0)\n",
    "bio_data0 = create_pref(bio, mode=0)\n",
    "sim_data1 = create_pref(sim, mode=1)\n",
    "bio_data1 = create_pref(bio, mode=1)\n",
    "sim_data2 = create_pref(sim, mode=2)\n",
    "bio_data2 = create_pref(bio, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_rf(ne_list, md_list, mss_list, X, y, cv=5):\n",
    "\n",
    "    best = [0.0, 0.0]\n",
    "    best_param = []\n",
    "\n",
    "    for ne in ne_list:\n",
    "        for md in md_list:\n",
    "            for mss in mss_list:\n",
    "                    \n",
    "                    rf = RandomForestClassifier(n_estimators=ne, max_depth=md, min_samples_split=mss)\n",
    "\n",
    "                    scores = cross_val_score(rf, X, y, cv=cv)\n",
    "                    if scores.mean() > best[0]:\n",
    "                        best = [scores.mean(), scores.std()]\n",
    "                        best_param = [ne, md, mss]\n",
    "                        print(\"best param: \", ne, md, mss)\n",
    "                        print(\"best acc: \", best[0], best[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.9218956898990852 0.02865741467929385\n",
      "best param:  50 8 5\n",
      "best acc:  0.9236310478166556 0.025175969011542627\n",
      "best param:  50 8 10\n",
      "best acc:  0.9249306799962275 0.030736953884597025\n",
      "best param:  50 12 2\n",
      "best acc:  0.925804017730831 0.033036644254497524\n",
      "best param:  50 12 5\n",
      "best acc:  0.9292728473073659 0.0322930152890416\n",
      "best param:  50 16 2\n",
      "best acc:  0.9323097236631142 0.02480482307886147\n",
      "best param:  100 32 2\n",
      "best acc:  0.9336112421012921 0.023845984313836176\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data0[:, :-1], sim_data0[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.9366518909742526 0.03668526283071027\n",
      "best param:  50 12 2\n",
      "best acc:  0.9500971423182119 0.02711803247544511\n",
      "best param:  100 32 2\n",
      "best acc:  0.9514014901442988 0.022389563171431728\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data1[:, :-1], sim_data1[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.9288371215693673 0.036986646263492455\n",
      "best param:  50 8 5\n",
      "best acc:  0.9297048005281525 0.038119665014149526\n",
      "best param:  50 12 2\n",
      "best acc:  0.9388163727247004 0.028414689358960674\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data2[:, :-1], sim_data2[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  1.0\n",
      "test acc:  0.952819956616052\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sim_data2[:, :-1], sim_data2[:, -1], test_size=0.8, random_state=114514)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=1)\n",
    "\n",
    "rf.fit(X_train, y_train.reshape(-1))\n",
    "print(\"train acc: \", accuracy_score(y_true=y_train, y_pred=rf.predict(X_train)))\n",
    "print(\"test acc: \", accuracy_score(y_true=y_test, y_pred=rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.72046875 0.014785246552729525\n",
      "best param:  50 8 20\n",
      "best acc:  0.72265625 0.026773062488254885\n",
      "best param:  100 8 10\n",
      "best acc:  0.7254687500000001 0.021950761661044944\n",
      "best param:  200 8 10\n",
      "best acc:  0.72609375 0.023147159990482603\n",
      "best param:  200 8 20\n",
      "best acc:  0.7284375 0.025129547163150388\n"
     ]
    }
   ],
   "source": [
    "X, y = bio_data0[:, :-1], bio_data0[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.714375 0.06656249999999998\n",
      "best param:  50 8 5\n",
      "best acc:  0.71671875 0.07061670305246488\n",
      "best param:  50 8 20\n",
      "best acc:  0.7215625 0.06061332039556155\n",
      "best param:  100 8 10\n",
      "best acc:  0.7225 0.06354094091115585\n"
     ]
    }
   ],
   "source": [
    "X, y = bio_data1[:, :-1], bio_data1[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  50 8 2\n",
      "best acc:  0.7120312500000001 0.061292236712735496\n",
      "best param:  50 8 5\n",
      "best acc:  0.724375 0.06192982104265277\n",
      "best param:  50 8 20\n",
      "best acc:  0.7259375 0.05306384347533636\n"
     ]
    }
   ],
   "source": [
    "X, y = bio_data2[:, :-1], bio_data2[:, -1]\n",
    "\n",
    "cross_val_rf(ne_list=[50,100,200], md_list=[8,12,16,32,None], mss_list=[2,5,10,20], X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  0.8875\n",
      "test acc:  0.8123046875\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    bio_data2[:, :-1], bio_data2[:, -1], test_size=0.8, random_state=114514)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=8, min_samples_split=10)\n",
    "\n",
    "rf.fit(X_train, y_train.reshape(-1))\n",
    "print(\"train acc: \", accuracy_score(y_true=y_train, y_pred=rf.predict(X_train)))\n",
    "print(\"test acc: \", accuracy_score(y_true=y_test, y_pred=rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.746875  , 0.7390625 , 0.78203125, 0.59375   , 0.703125  ]),\n",
       " 0.7129687499999999,\n",
       " 0.06466862647373917)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X=bio_data2[:, :-1], y=bio_data2[:, -1], cv=5)\n",
    "scores, scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_gp(kernel_list, X, y, cv=5):\n",
    "\n",
    "    best = [0.0, 0.0]\n",
    "    best_param = []\n",
    "\n",
    "    for kernel in kernel_list:\n",
    "                \n",
    "        gpc = GaussianProcessClassifier(kernel=kernel).fit(X, y)\n",
    "\n",
    "        scores = cross_val_score(gpc, X, y, cv=cv)\n",
    "        if scores.mean() > best[0]:\n",
    "            best = [scores.mean(), scores.std()]\n",
    "            print(\"best kernel: \", kernel)\n",
    "            print(\"best acc: \", best[0], best[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_list = [\n",
    "    1.0 * RBF(1.0), \n",
    "    1.0 * Matern(1.0), \n",
    "    1.0 * RationalQuadratic(1.0), \n",
    "    1.0 * ExpSineSquared(1.0), \n",
    "    1.0 * DotProduct(1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best kernel:  1**2 * RBF(length_scale=1)\n",
      "best acc:  0.6141497689333207 0.0005338111855135441\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data0[:, :-1], sim_data0[:, -1]\n",
    "\n",
    "cross_val_gp(kernel_list=kernel_list, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best kernel:  1**2 * RBF(length_scale=1)\n",
      "best acc:  0.6141497689333207 0.0005338111855135441\n"
     ]
    }
   ],
   "source": [
    "X, y = sim_data1[:, :-1], sim_data1[:, -1]\n",
    "\n",
    "cross_val_gp(kernel_list=kernel_list, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best kernel:  1**2 * RBF(length_scale=1)\n",
      "best acc:  0.6884375 0.0003125000000000267\n"
     ]
    }
   ],
   "source": [
    "X, y = bio_data0[:, :-1], bio_data0[:, -1]\n",
    "\n",
    "cross_val_gp(kernel_list=kernel_list, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = bio_data1[:, :-1], bio_data1[:, -1]\n",
    "\n",
    "cross_val_gp(kernel_list=kernel_list, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
