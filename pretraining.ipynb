{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE, LocallyLinearEmbedding, Isomap, MDS, SpectralEmbedding\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # data preprocessing\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# trainTransform  = tv.transforms.Compose([tv.transforms.ToTensor(), tv.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# trainset = tv.datasets.MNIST(root='./data',  train=True, download=False, transform=transform)\n",
    "# testset = tv.datasets.MNIST(root='./data',  train=False, download=False, transform=transform)\n",
    "\n",
    "# X_train = [i[0].reshape(-1) for i in trainset]\n",
    "# X_train = torch.vstack(X_train)\n",
    "# y_train = torch.tensor([i[1] for i in trainset])\n",
    "# print(\"X_train.shape: {}\".format(X_train.shape))        # X_train.shape: torch.Size([60000, 1, 28, 28])\n",
    "\n",
    "# X_test = [i[0].reshape(-1) for i in testset]\n",
    "# X_test = torch.vstack(X_test)\n",
    "# y_test = torch.tensor([i[1] for i in testset])\n",
    "# print(\"X_test.shape: {}\".format(X_test.shape))          # X_test.shape: torch.Size([10000, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"./data/MNIST/X_train.npy\", X_train)\n",
    "# np.save(\"./data/MNIST/y_train.npy\", y_train)\n",
    "# np.save(\"./data/MNIST/X_test.npy\", X_test)\n",
    "# np.save(\"./data/MNIST/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 784), y_train: (60000,)\n",
      "X_test: (10000, 784), y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load(\"./data/MNIST/X_train.npy\")\n",
    "y_train = np.load(\"./data/MNIST/y_train.npy\")\n",
    "X_test = np.load(\"./data/MNIST/X_test.npy\")\n",
    "y_test = np.load(\"./data/MNIST/y_test.npy\")\n",
    "\n",
    "print(\"X_train: {}, y_train: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"X_test: {}, y_test: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(X, y, model_name='t-sne', n_neighbors=10):\n",
    "\n",
    "    if model_name=='pca':\n",
    "        pca = PCA(n_components=2)\n",
    "        z = pca.fit_transform(X)\n",
    "    elif model_name=='lle_ltsa':\n",
    "        lle_ltsa = LocallyLinearEmbedding(method=\"ltsa\", n_components=2, n_neighbors=n_neighbors)\n",
    "        z = lle_ltsa.fit_transform(X)\n",
    "    elif model_name=='lle_hessian':\n",
    "        lle_hessian = LocallyLinearEmbedding(method=\"hessian\", n_components=2, n_neighbors=n_neighbors)\n",
    "        z = lle_hessian.fit_transform(X)\n",
    "    elif model_name=='lle_mod':\n",
    "        lle_mod = LocallyLinearEmbedding(method=\"modified\", n_components=2, n_neighbors=n_neighbors)\n",
    "        z = lle_mod.fit_transform(X)\n",
    "    elif model_name=='isomap':\n",
    "        isomap = Isomap(n_neighbors=5, n_components=2, p=1)\n",
    "        z = isomap.fit_transform(X)\n",
    "    elif model_name=='mds':\n",
    "        mds = MDS(n_components=2)\n",
    "        z = mds.fit_transform(X)\n",
    "    elif model_name=='spectralembedding':\n",
    "        se = SpectralEmbedding(n_components=2, n_neighbors=n_neighbors)\n",
    "        z = se.fit_transform(X)\n",
    "    elif model_name=='lda':\n",
    "        lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "        z = lda.fit_transform(X_train, y_train)\n",
    "    else:\n",
    "        print(\"wrong model name\")\n",
    "        exit()\n",
    "\n",
    "    z = normalise(z=z)\n",
    "\n",
    "    scags = scagnostics.compute(z[:, 0], z[:, 1])\n",
    "    scags = torch.tensor([list(scags.values())]).view(1,-1)\n",
    "\n",
    "    return z, y, scags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca, 5\n",
      "pca, 10\n",
      "pca, 15\n",
      "lle_ltsa, 5\n",
      "wrong param\n",
      "lle_ltsa, 10\n"
     ]
    }
   ],
   "source": [
    "model_names = ['pca', 'lle_ltsa', 'lle_hessian', 'lle_mod', 'isomap', 'mds', 'spectralembedding', 'lda']\n",
    "n_neighbors = [5, 10, 15]\n",
    "\n",
    "cnt = 0\n",
    "for model_name in model_names:\n",
    "    for neighbor in n_neighbors:\n",
    "        print(\"{}, {}\".format(model_name, neighbor))\n",
    "        try:\n",
    "            z, y, scags = generate(X_train, y_train, model_name=model_name, n_neighbors=neighbor)\n",
    "            torch.save([model_name, neighbor, z, y, scags], \"./data/pretraining/{}.pt\".format(cnt))\n",
    "            cnt += 1\n",
    "        except:\n",
    "            print(\"wrong param\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pretraining Metric-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pretraining HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
