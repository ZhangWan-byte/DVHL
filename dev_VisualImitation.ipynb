{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.load(open(\"./tsne_data_reducted_normalised.npy\", \"rb\"))\n",
    "Z = torch.tensor(Z, requires_grad=True, dtype=float)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# develop VisualImitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myact(x):\n",
    "    # return nn.Sigmoid()(x)\n",
    "    return nn.Tanh()(x*100000)\n",
    "\n",
    "# a = torch.arange(start=-1,end=1,step=0.0001,dtype=float)\n",
    "# b = myact(a)\n",
    "\n",
    "# plt.plot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m(zi, pts=0):\n",
    "    a0 = torch.ones((1000,1000), requires_grad=True)\n",
    "    a = a0 * zi[0] * 1000\n",
    "    b0 = torch.ones((1000,1000), requires_grad=True)\n",
    "    b = b0 * zi[1] * 1000\n",
    "    if pts==0:\n",
    "        gridx = torch.arange(1,1001)\n",
    "        gridy = torch.arange(1,1001)\n",
    "    elif pts==1:\n",
    "        gridx = torch.arange(0,1000)\n",
    "        gridy = torch.arange(1,1001)\n",
    "    elif pts==2:\n",
    "        gridx = torch.arange(2,1002)\n",
    "        gridy = torch.arange(2,1002)\n",
    "    elif pts==3:\n",
    "        gridx = torch.arange(1,1001)\n",
    "        gridy = torch.arange(0,1000)\n",
    "\n",
    "    x_new = myact(a-gridx)\n",
    "    y_new = myact(b-gridy.reshape(-1,1))\n",
    "    m = myact(x_new*y_new)\n",
    "\n",
    "    return x_new, y_new, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.nn.Conv2d(1, 1, (3, 3), stride=1, padding=1, bias=False)\n",
    "f.weight.data = torch.Tensor([[[[0, 1, 0],\n",
    "                                [1, 0, 1],\n",
    "                                [0, 1, 0]]]])\n",
    "\n",
    "\n",
    "def myfunc(z, label=0, size=1000):\n",
    "    # mask = torch.zeros((1000,1000), dtype=float)\n",
    "    # i = torch.floor(z[0]*size).type(torch.LongTensor)\n",
    "    # j = torch.floor(z[1]*size).type(torch.LongTensor)\n",
    "    # print(i.dtype)\n",
    "    # mask[i][j] = 1\n",
    "\n",
    "    # _, _, mask1 = get_m(zi=z, pts=1)\n",
    "    # _, _, mask3 = get_m(zi=z, pts=3)\n",
    "\n",
    "    # mask = mask1 * mask3\n",
    "\n",
    "    # masks = torch.sigmoid((f(mask.unsqueeze(0).unsqueeze(0)).squeeze()-3)*1000)\n",
    "\n",
    "    # get mask_mat at point i\n",
    "    _, _, mask1 = get_m(zi=z[:2], pts=1)\n",
    "    _, _, mask3 = get_m(zi=z[:2], pts=3)\n",
    "\n",
    "    # get the ultimate 0-1 mask\n",
    "    mask = (mask1 * mask3 - 1) / 2 * (-1)\n",
    "    mask = torch.transpose(mask, 0, 1)\n",
    "\n",
    "    masks = torch.sigmoid((f(mask.unsqueeze(0).unsqueeze(0)).squeeze()-3)*1000)\n",
    "    masks = masks * (z[2]+1)\n",
    "\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6714, 0.8661, 4.0000], dtype=torch.float64, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, mask1 = get_m(zi=Z[2, :2], pts=1)\n",
    "_, _, mask3 = get_m(zi=Z[2, :2], pts=3)\n",
    "\n",
    "mask = (mask1 * mask3 - 1) / 2 * (-1)\n",
    "mask = torch.transpose(mask, 0, 1)\n",
    "\n",
    "masks = torch.sigmoid((f(mask.unsqueeze(0).unsqueeze(0)).squeeze()-3)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask1[671, 866]\n",
    "\n",
    "k = 3\n",
    "(1/2-mask1 * mask3/2)[(866-k):(866+k+1),(671-k):(671+k+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
       "         [ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
       "         [ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ...,  1.,  1.,  1.],\n",
       "         [-1., -1., -1.,  ...,  1.,  1.,  1.],\n",
       "         [-1., -1., -1.,  ...,  1.,  1.,  1.]], grad_fn=<TanhBackward0>),\n",
       " tensor([[-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         ...,\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1, (mask1 * mask3 - 1) / 2 * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., -0., 1., -0., -0., -0.],\n",
       "        [-0., -0., -0., 1., -0., -0., -0.],\n",
       "        [-0., -0., -0., 1., -0., -0., -0.],\n",
       "        [1., 1., 1., -0., 1., 1., 1.],\n",
       "        [-0., -0., -0., 1., -0., -0., -0.],\n",
       "        [-0., -0., -0., 1., -0., -0., -0.],\n",
       "        [-0., -0., -0., 1., -0., -0., -0.]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "mask[(671-k):(671+k+1),(866-k):(866+k+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1000]),\n",
       " tensor([[-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         ...,\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., -0., -0.]], grad_fn=<TransposeBackward0>))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = masks * (Z[2, 2]+1)\n",
    "\n",
    "# transform mask matrix to onehot form\n",
    "masks = masks.reshape(1000*1000,1)\n",
    "\n",
    "res = F.one_hot(masks.long(), num_classes=11)\n",
    "res = res.squeeze().reshape(1000,1000,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1000000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1000, 11])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res[831][524]\n",
    "res[671][866]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\DV_HL\\demo_VisualImitation.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DV_HL/demo_VisualImitation.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DV_HL/demo_VisualImitation.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res[i])):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DV_HL/demo_VisualImitation.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mif\u001b[39;00m res[i][j]\u001b[39m.\u001b[39;49margmax()\u001b[39m.\u001b[39mitem()\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DV_HL/demo_VisualImitation.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             \u001b[39mprint\u001b[39m(i, j)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(res)):\n",
    "    for j in range(len(res[i])):\n",
    "        if res[i][j].argmax().item()!=0:\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc1(masks, size=1000):\n",
    "    # transform mask matrix to onehot form\n",
    "    masks = masks.reshape(size*size,1)\n",
    "    res = F.one_hot(masks.long(), num_classes=11)\n",
    "    res = res.squeeze().reshape(size,size,-1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z1024 = Z[:1024].detach()\n",
    "z1024 = Z[:64].detach()\n",
    "z1024.requires_grad_(True)\n",
    "z1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = torch.vmap(myfunc)(z1024)\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks1 = torch.sum(masks, dim=0)\n",
    "masks1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import draw_Ihat\n",
    "\n",
    "draw_Ihat(I_hat=masks1.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = myfunc1(masks1)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.ones((1000,1000,11))\n",
    "label = label.type(torch.DoubleTensor)\n",
    "label.requires_grad_(False)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_hat = res * label\n",
    "I_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_hat1 = torch.sum(I_hat, dim=0)\n",
    "I_hat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = torch.randint(0,11,(1000,1000))\n",
    "gt = gt.type(torch.DoubleTensor)\n",
    "gt.requires_grad_(False)\n",
    "gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "loss = criterion(gt, I_hat1)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1024.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(z1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convolution to detect centre point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]]], dtype=torch.float64),\n",
       " torch.Size([1, 1, 11, 11]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.zeros((11,11), dtype=float)\n",
    "\n",
    "mat[5,:] = torch.ones((mat[5,:].shape))\n",
    "mat[:, 5] = torch.ones((mat[:,5].shape))\n",
    "mat[5,5] = 0\n",
    "mat = mat.unsqueeze(0).unsqueeze(0)\n",
    "mat, mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 1., 0.],\n",
       "           [1., 0., 1.],\n",
       "           [0., 1., 0.]]]]),\n",
       " torch.Size([1, 1, 3, 3]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.nn.Conv2d(1, 1, (3, 3), stride=1, bias=False)\n",
    "c.weight.data = torch.Tensor([[[[0, 1, 0],\n",
    "                                [1, 0, 1],\n",
    "                                [0, 1, 0]]]])\n",
    "c.weight.data, c.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 2., 1., 2., 1., 1., 1.],\n",
       "          [2., 2., 2., 1., 4., 1., 2., 2., 2.],\n",
       "          [1., 1., 1., 2., 1., 2., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = c(mat.float())\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 2., 1., 2., 1., 1., 1.],\n",
       "          [2., 2., 2., 1., 4., 1., 2., 2., 2.],\n",
       "          [1., 1., 1., 2., 1., 2., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 2., 1., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_weights = torch.Tensor([[[[0, 1, 0],\n",
    "                            [1, 0, 1],\n",
    "                            [0, 1, 0]]]])\n",
    "res = F.conv2d(input=mat.float(), weight=conv_weights)                            \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.relu(res-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = torch.sigmoid((res-3)*1000)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 9, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demo VisualImitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from models import *\n",
    "\n",
    "VImodule = VisualImitation(size=1000, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3]), True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z = minmax(Z[128:256, :]).cuda()\n",
    "z = Z[:16, :].cuda()\n",
    "# z = Z[:16, :]\n",
    "# z = Z[128:256, :].cuda()\n",
    "z.shape, z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1000, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I_hat_onehot, I_hat = VImodule(z)\n",
    "# I_hat.shape\n",
    "\n",
    "I_hat = VImodule(z)\n",
    "I_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_hat.requires_grad, z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(4, device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 16 datapoints: 5, 0, 4\n",
    "torch.argmax(I_hat[540][457]), torch.argmax(I_hat[831][524]), torch.argmax(I_hat[671][866])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_Ihat(I_hat=I_hat.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.ones(I_hat.shape, dtype=float).cuda()\n",
    "I_hat.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(213.0450, dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(Z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 234.1367,    0.5643,    0.0000],\n",
       "        [ 184.6781,    6.6765,    0.0000],\n",
       "        [   7.7590,  214.8650,    0.0000],\n",
       "        [  81.8656, -110.8391,    0.0000],\n",
       "        [  44.3037,  -77.7883,    0.0000],\n",
       "        [ -91.8296,   31.5204,    0.0000],\n",
       "        [  37.9358,   76.8595,    0.0000],\n",
       "        [ -47.8311,  -26.7553,    0.0000],\n",
       "        [-199.3432,   17.5768,    0.0000],\n",
       "        [  38.7834, -132.9752,    0.0000],\n",
       "        [ -31.1355, -162.3155,    0.0000],\n",
       "        [   2.9657,  223.3813,    0.0000],\n",
       "        [ 188.2117,   23.6953,    0.0000],\n",
       "        [-128.5100,  -49.4858,    0.0000],\n",
       "        [  48.6961,   13.2325,    0.0000],\n",
       "        [-208.9322,    3.0784,    0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.grad[:16, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
