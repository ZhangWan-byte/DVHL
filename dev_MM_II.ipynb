{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2697986, 11289915, 13987901)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MMModel(MM_I_wPATH=\"./results/encoder_weights.pt\", MM_II_wPATH=None, freeze=(False, False), device=torch.device('cpu'))\n",
    "\n",
    "param1 = sum(p.numel() for p in model.MM_I.parameters() if p.requires_grad)\n",
    "param2 = sum(p.numel() for p in model.MM_II.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "param1, param2, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11224164"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.MM_II.cnn.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4953444"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "sum(p.numel() for p in resnet.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.ones((1,10,1000,1000))\n",
    "out = resnet(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainTransform  = tv.transforms.Compose([tv.transforms.ToTensor(), tv.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = tv.datasets.MNIST(root='./data',  train=True,download=True, transform=transform)\n",
    "testset = tv.datasets.MNIST(root='./data',  train=False,download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = [i[0] for i in trainset]\n",
    "trainlabel = [i[1] for i in trainset]\n",
    "testdata = [i[0] for i in testset]\n",
    "testlabel = [i[1] for i in testset]\n",
    "\n",
    "X = traindata + testdata\n",
    "y = trainlabel + testlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.vstack(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.unsqueeze(1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z, answers = model()\n",
    "\n",
    "z = np.load(\"./tsne_data_reducted_normalised.npy\")\n",
    "z = torch.tensor(z)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./metrics/get_scag.r\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HumanModel' object has no attribute 'pref_mlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\DV_HL\\dev_MM_II.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DV_HL/dev_MM_II.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# I_hat = model.VI(z)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DV_HL/dev_MM_II.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m I_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((\u001b[39m1\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m1000\u001b[39m,\u001b[39m1000\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DV_HL/dev_MM_II.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m answers \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mMM_II(I_hat\u001b[39m=\u001b[39;49mI_hat, z\u001b[39m=\u001b[39;49mz, labels\u001b[39m=\u001b[39;49my, x\u001b[39m=\u001b[39;49mX)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DV_HL/dev_MM_II.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mMM_II(z)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\DV_HL\\models\\HumanModel.py:132\u001b[0m, in \u001b[0;36mHumanModel.forward\u001b[1;34m(self, I_hat, z, labels, x)\u001b[0m\n\u001b[0;32m    130\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparameterise(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogvar)       \u001b[39m# random d for uncertainty\u001b[39;00m\n\u001b[0;32m    131\u001b[0m w \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_weights)                    \u001b[39m# quasi-binary w for personal preference over metrics\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m user_preference \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpref_mlp(m \u001b[39m*\u001b[39m d \u001b[39m*\u001b[39m w)          \u001b[39m# feature for user preference\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m# feature fusion\u001b[39;00m\n\u001b[0;32m    135\u001b[0m feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfusion(visual_feature, user_preference)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HumanModel' object has no attribute 'pref_mlp'"
     ]
    }
   ],
   "source": [
    "# I_hat = model.VI(z)\n",
    "I_hat = torch.ones((1,10,1000,1000))\n",
    "answers = model.MM_II(I_hat=I_hat, z=z, labels=y, x=X)\n",
    "\n",
    "out = model.MM_II(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
