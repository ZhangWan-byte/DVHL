{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321444"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [1,1,1,1])\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_hat = torch.ones((1,10,1000,1000))\n",
    "\n",
    "out = model(I_hat)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1254116"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [1,1,1,1])\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4953444"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [1,1,1,1])\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AttnFusion(visual_size=100, metric_size=9)\n",
    "visual = torch.ones((1,100))\n",
    "metric = torch.ones((1,9))\n",
    "\n",
    "feats = model(user_preference=metric, visual_feature=visual)\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2697986, 11277259, 13975245)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MMModel(MM_I_wPATH=\"./results/encoder_weights.pt\", MM_II_wPATH=None, freeze=(False, False), device=torch.device('cpu'))\n",
    "\n",
    "param1 = sum(p.numel() for p in model.MM_I.parameters() if p.requires_grad)\n",
    "param2 = sum(p.numel() for p in model.MM_II.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "param1, param2, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11224164"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.MM_II.cnn.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4953444"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "sum(p.numel() for p in resnet.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.ones((1,10,1000,1000))\n",
    "out = resnet(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainTransform  = tv.transforms.Compose([tv.transforms.ToTensor(), tv.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = tv.datasets.MNIST(root='./data',  train=True,download=True, transform=transform)\n",
    "testset = tv.datasets.MNIST(root='./data',  train=False,download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = [i[0] for i in trainset]\n",
    "trainlabel = [i[1] for i in trainset]\n",
    "testdata = [i[0] for i in testset]\n",
    "testlabel = [i[1] for i in testset]\n",
    "\n",
    "X = traindata + testdata\n",
    "y = trainlabel + testlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.vstack(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.unsqueeze(1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM_II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z, answers = model()\n",
    "\n",
    "z = np.load(\"./tsne_data_reducted_normalised.npy\")\n",
    "z = torch.tensor(z)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 1000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Ihat(Z):\n",
    "    mat = np.zeros((1000,1000))\n",
    "    for i in range(len(Z)):\n",
    "        xx = min(int(np.floor(Z[i,0]*1000)), 999)\n",
    "        yy = min(int(np.floor(Z[i,1]*1000)), 999)\n",
    "        mat[xx,yy] = Z[i, 2]\n",
    "    return mat\n",
    "\n",
    "# VI = VisualImitation(device='cpu')\n",
    "# I_hat = VI(z[:128,:])\n",
    "I_hat = get_Ihat(Z=z)\n",
    "I_hat = torch.tensor(I_hat).unsqueeze(0)\n",
    "I_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./metrics/get_scag.r\n"
     ]
    }
   ],
   "source": [
    "model = HumanModel(cnn_layers=[2,2,2,2], metric_num=9, hidden_dim=100)\n",
    "q1, q2, q3 = model(I_hat=torch.ones((1,10,1000,1000)), z=z[:1024,:2], labels=None, x=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5342]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4964]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.5380]], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1, q2, q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MMModel(MM_I_wPATH=\"./results/encoder_weights.pt\", MM_II_wPATH=None, freeze=(False, False), device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\DV_HL\\dev_MM_II.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DV_HL/dev_MM_II.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m VI \u001b[39m=\u001b[39m VisualImitation(device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DV_HL/dev_MM_II.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m I_hat \u001b[39m=\u001b[39m VI(torch\u001b[39m.\u001b[39;49mones((\u001b[39m128\u001b[39;49m,\u001b[39m2\u001b[39;49m)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DV_HL/dev_MM_II.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m I_hat\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\DV_HL\\models\\VIModules.py:120\u001b[0m, in \u001b[0;36mVisualImitation.forward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, z):\n\u001b[0;32m    115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"calculate I_hat\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[39m    :param z: [N, 3] - coordinates and data class\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     I_hat_single \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_I_hat_single(z)\n\u001b[0;32m    121\u001b[0m     \u001b[39m# I_hat_single.register_hook(save_grad('I_hat_single'))\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     I_hat, _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(I_hat_single, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\DV_HL\\models\\VIModules.py:105\u001b[0m, in \u001b[0;36mVisualImitation.get_I_hat_single\u001b[1;34m(self, z, size)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m# get masks\u001b[39;00m\n\u001b[0;32m    104\u001b[0m masks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([mask_mat]\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m labels \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(z[:, \u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39mlong(), num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m    107\u001b[0m \u001b[39m# calculate final I_hat\u001b[39;00m\n\u001b[0;32m    108\u001b[0m I_hat_single \u001b[39m=\u001b[39m masks \u001b[39m*\u001b[39m labels\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 1 with size 2"
     ]
    }
   ],
   "source": [
    "VI = VisualImitation(device='cpu')\n",
    "I_hat = VI(torch.ones((128,2)))\n",
    "I_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([6, 1, 28, 28]), labels:torch.Size([6, 1])\n",
      "z:torch.Size([6, 2])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\DV_HL\\dev_MM_II.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DV_HL/dev_MM_II.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m q1, q2, q3 \u001b[39m=\u001b[39m model(x\u001b[39m=\u001b[39;49mX[:\u001b[39m6\u001b[39;49m], labels\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor(y[:\u001b[39m6\u001b[39;49m])\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\DV_HL\\models\\MMModel.py:45\u001b[0m, in \u001b[0;36mMMModel.forward\u001b[1;34m(self, x, labels)\u001b[0m\n\u001b[0;32m     43\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMM_I(x)\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mz:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(z\u001b[39m.\u001b[39mshape))\n\u001b[1;32m---> 45\u001b[0m I_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mVI(z)\n\u001b[0;32m     47\u001b[0m answers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMM_II(I_hat\u001b[39m=\u001b[39mI_hat, z\u001b[39m=\u001b[39mz, labels\u001b[39m=\u001b[39mlabels, x\u001b[39m=\u001b[39mx)\n\u001b[0;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m z, answers\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\DV_HL\\models\\VIModules.py:120\u001b[0m, in \u001b[0;36mVisualImitation.forward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, z):\n\u001b[0;32m    115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"calculate I_hat\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[39m    :param z: [N, 3] - coordinates and data class\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     I_hat_single \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_I_hat_single(z)\n\u001b[0;32m    121\u001b[0m     \u001b[39m# I_hat_single.register_hook(save_grad('I_hat_single'))\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     I_hat, _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(I_hat_single, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\DV_HL\\models\\VIModules.py:105\u001b[0m, in \u001b[0;36mVisualImitation.get_I_hat_single\u001b[1;34m(self, z, size)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m# get masks\u001b[39;00m\n\u001b[0;32m    104\u001b[0m masks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([mask_mat]\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m labels \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(z[:, \u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39mlong(), num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m    107\u001b[0m \u001b[39m# calculate final I_hat\u001b[39;00m\n\u001b[0;32m    108\u001b[0m I_hat_single \u001b[39m=\u001b[39m masks \u001b[39m*\u001b[39m labels\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 1 with size 2"
     ]
    }
   ],
   "source": [
    "q1, q2, q3 = model(x=X[:6], labels=torch.tensor(y[:6]).reshape(-1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
